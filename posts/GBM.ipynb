{
 "cells": [
  {
   "cell_type": "raw",
   "id": "06887f45-f6f1-4eab-aea5-c2881eb43a39",
   "metadata": {},
   "source": [
    "---\n",
    "\"title\": \"GBM\"\n",
    "\"author\": \"이정재\"\n",
    "\"date\": \"2024-03-16\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d2dc6-6719-4fec-945f-438d3ecdfc96",
   "metadata": {},
   "source": [
    "# GBM (Gradient Boosting Machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb23aea-033c-4cbe-b900-6471ea2334ad",
   "metadata": {},
   "source": [
    " `-` 다음은 [wikipedia](https://en.wikipedia.org/wiki/Gradient_boosting)의 Gradient Boosting Algorithm이다. 다음의 수식을 먼저 읽고 최대한 이해하려고 노력해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c690650a-1a0b-4a44-b276-bbedf0631fb7",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85e3b9c-7f54-4964-9a42-de63226f4146",
   "metadata": {},
   "source": [
    "1. **initialize model with a constant value:**\\\n",
    "    $F_0(x) = \\underset{\\gamma}{\\arg\\min}\\sum_{i=1}^n L(y_i, \\gamma)$\n",
    "\n",
    " 2. **For m = 1 to M**: \n",
    "    1. Compute so-called pseudo-residuals\n",
    "       $r_{im} = - \\Bigg[\\displaystyle\\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}\\Bigg]_{F(x) = F_{m-1}(x)}$ for $i = 1, ... ,n$\n",
    "    2. Fit a base learner (or weak learner, e.g. tree) closed under scaling $h_m(x)$ to pseuo-residuals, i.e. train it using the training set $\\{(x_i, r_{im})\\}_{i=1}^{n}$\n",
    "    3. Compute multiplier $\\gamma_{m}$ by solving the following one-dimensional optimization problem:\\\n",
    "       $\\gamma_m = \\underset{\\gamma}{\\arg\\min}\\sum_{i=1}^n L(y_i, F_{m-1}(x_i) + \\gamma h_m(x_i))$\n",
    "    4. Update the model:\\\n",
    "       $F_m(x) = F_{m-1}(x) + \\gamma_m h_m(x)$\n",
    "    \n",
    "3. **Output $\\hat{f(x)} = F_M(x)$**\n",
    "\n",
    "   \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1633e-76e4-4180-9ff1-64434be59955",
   "metadata": {},
   "source": [
    "수식으로만 완전히 이해하기가 어렵기 때문에 간단한 예시와 `pandas dataframe`을 이용하여 설명해보겠습니다.\\\n",
    "다음과 같은 데이터가 있다고 가정해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504f9bae-f503-421c-b970-31e8f7723ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>공부시간(m)</th>\n",
       "      <th>성별</th>\n",
       "      <th>수학점수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>여</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>남</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>남</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>여</td>\n",
       "      <td>???</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   공부시간(m) 성별 수학점수\n",
       "0      150  여   90\n",
       "1      120  남   65\n",
       "2       60  남   55\n",
       "3       80  여  ???"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame({'공부시간(m)':[150, 120, 60, 80], '성별':['여','남','남', '여'], '수학점수':[90, 65, 55, '???']})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f94e32-8ce5-4610-ba34-cd5cb1b40c18",
   "metadata": {},
   "source": [
    "다음과 같은 데이터가 있다고 할 때, 저희는 `공부시간(m)`을 통하여 `수학점수`를 예측하고 싶습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749d8713-a542-40ad-b3f1-7d85ce24da05",
   "metadata": {},
   "source": [
    "#### **1단계**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb22f3-c964-48d6-9676-d158be35996b",
   "metadata": {},
   "source": [
    "1. **initialize model with a constant value:**\\\n",
    "    $F_0(x) = \\underset{\\gamma}{\\arg\\min}\\sum_{i=1}^n L(y_i, \\gamma)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0818ff-f100-4ff4-8e9d-6e32c1e042fa",
   "metadata": {},
   "source": [
    "1. 초기모델을 상수로 정의합니다. 여기서 상수는 $y_i$와 $\\gamma$입니다.\n",
    "2. $y_i$는 수학점수를 의미하고 $\\gamma $는 초기 예측값입니다.\n",
    "    - $y_1$ = 90,  $y_2$ = 65, $y_3$ = 60\n",
    "3. 여기서의 Loss Function $L(y_i, \\gamma) = \\displaystyle\\frac1n \\sum_{i=1}^{n} (y_i - \\gamma)^2$입니다. (잘 모르시는 분들은 MSE 학습하시면 좋을 것 같습니다.)\n",
    "4. 예시의 수치를 대입하면\\\n",
    "$L(y_i, \\gamma) = \\displaystyle\\frac13 \\sum_{i=1}^{3} (y_i - \\gamma)^2 =  \\displaystyle\\frac13(90 - \\gamma)^2 + \\displaystyle\\frac13(65 - \\gamma)^2 + \\displaystyle\\frac13(55 - \\gamma)^2$입니다.\n",
    "5. $L(y_i, \\gamma)$가 최소가 되는 $\\gamma$를 찾아야 하므로\n",
    "$\\displaystyle\\frac{\\partial L}{\\partial \\gamma} = \\displaystyle\\frac23(\\gamma - 90) + \\displaystyle\\frac23(\\gamma - 65) + \\displaystyle\\frac23(\\gamma - 55) = \\displaystyle\\frac23(3\\gamma - 210)$입니다.\n",
    "6. $\\displaystyle\\frac{\\partial L}{\\partial \\gamma} = 0$이 되어야 하므로 $\\gamma$ = 70입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327979e8-05d5-49de-a3cc-f822bfe86a02",
   "metadata": {},
   "source": [
    "#### **2단계**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69fa9a9-f775-431f-bc29-8bf29e032d59",
   "metadata": {},
   "source": [
    "\n",
    " 2. **For $m$ = 1 to $M$**: \n",
    "    1. Compute so-called pseudo-residuals\n",
    "       $r_{im} = - \\Bigg[\\displaystyle\\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}\\Bigg]_{F(x) = F_{m-1}(x)}$ for $i = 1, ... ,n$\n",
    "    2. Fit a base learner (or weak learner, e.g. tree) closed under scaling $h_m(x)$ to pseuo-residuals, i.e. train it using the training set $\\{(x_i, r_{im})\\}_{i=1}^{n}$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f6caff-e077-44d2-ab31-30c025ab1da4",
   "metadata": {},
   "source": [
    "$r_{im}$은 가짜 잔차(pseudo-residuals)라고 부릅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f2d26e-95e5-452a-aa94-4b3da1b8705a",
   "metadata": {},
   "source": [
    "$L(y_i, F(x_i)) = \\displaystyle\\frac1n \\sum_{i=1}^{n}(y_i - F(x_i))^2$이므로\\\n",
    "$r_{im} = -\\Bigg[\\displaystyle\\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)} \\Bigg]_{F(x)=F_{m-1}(x)} =\\displaystyle\\frac2n\\sum_{i=1}^{n}(y_i - F_{m-1}(x_i))$입니다. 정리하면,\\\n",
    "$r_{im} = \\displaystyle\\frac2n\\sum_{i=1}^{n}(y_i - F_{m-1}(x_i))$입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7effbc3e-6e52-48b0-a4f4-3e4e4781c744",
   "metadata": {},
   "source": [
    "1. 여기서 $M$은 예측기의 개수, $n$은 데이터의 개수입니다.\n",
    "2. For $m$ = 1 to $M$의 의미는 M개의 예측기에 대해서 특정 작업을 수행한다는 의미입니다.\n",
    "3. for $i$ = $1, ... ,n$은 $n$개의 설명변수 $x$에 대해서 $x_1$부터 $x_n$까지 특정 작업을 수행한다는 의미입니다.\n",
    "4. $r_{im}$은 가짜 잔차(pseudo-residuals)라고 부릅니다.\n",
    "5. $(m-1)$번째 학습한 모델은 $F_{m-1}(x)$입니다. 이떄의 Loss Function을 $F_{m-1}(x)$로 미분한 것이 $-r_{im}$입니다.\n",
    "6. 식을 확인해보면 실제 잔차$(y_i - F_{m-1}(x))$와 유사해서 가짜 잔차로 불립니다.\n",
    "7. 이때 $h_{m}(x)$는 가짜 잔차를 학습합니다.\n",
    "8. 즉, $h_{m}(x) = \\widehat{y-F_{m-1}(x)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d257c053-1b0c-4009-b3ed-4937febcf9b7",
   "metadata": {},
   "source": [
    "#### **3단계**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d849874f-5d52-45a9-88b2-414e21264eba",
   "metadata": {},
   "source": [
    "2. **For m = 1 to M**:\\\n",
    "    C. Compute multiplier $\\gamma_{m}$ by solving the following one-dimensional optimization problem:\\\n",
    "       $\\gamma_m = \\underset{\\gamma}{\\arg\\min}\\sum_{i=1}^n L(y_i, F_{m-1}(x_i) + \\gamma h_m(x_i))$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52ce8a-3fce-40d1-b390-aab9309641a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6791d4a1-81a3-4bfe-965f-089c35127c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
