{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 로지스틱회귀\n",
        "\n",
        "이정재  \n",
        "2024-03-24\n",
        "\n",
        "## 로지스틱 회귀(Logistic Regression)\n",
        "\n",
        "### 베르누이 분포\n",
        "\n",
        "-   $f(x|p) = p^x(1-p)^{1-x} (x=1,0)$\n",
        "-   즉 $x=1$일 확률이 $p$, $x=0$일 확률이 $1-p$입니다.\n",
        "\n",
        "### 승산비($odds\\,ratio$)\n",
        "\n",
        "-   베르누이 분포에서 1이 나올 확률 $p$와 0이 나올 확률 $1-p$의\n",
        "    비율입니다.\n",
        "-   $odds\\, ratio = \\displaystyle\\frac{p}{1-p}    \\left(0\\leq odds\\,ratio\\leq \\infty \\right) = \\displaystyle\\frac{\\text{1일확률}}{\\text{0일확률}}$\n",
        "-   확률 $p$를 $odds\\,ratio$로 변환하면 0부터 무한대까지의 값을 가질 수\n",
        "    있다.\n",
        "-   승산비($odds\\,ratio$)를 로그변환하면 다음과 같다.\n",
        "-   $z = logit\\left(\\displaystyle\\frac{p}{1-p} \\right) = log\\left(\\displaystyle\\frac{p}{1-p}\\right)$\n",
        "\n",
        "`-` 식을 다음과 같이 변환해보자  \n",
        "$log\\left(\\displaystyle\\frac{p}{1-p}\\right) = z$  \n",
        "  \n",
        "$\\Leftrightarrow \\displaystyle\\frac{p}{1-p} = e^z$  \n",
        "  \n",
        "$\\Leftrightarrow p = e^z(1-p)$  \n",
        "  \n",
        "$\\Leftrightarrow p = e^z - pe^k$  \n",
        "  \n",
        "$\\Leftrightarrow p(1+e^z) = e^z$  \n",
        "  \n",
        "$\\Leftrightarrow p = \\displaystyle\\frac{e^z}{1+e^z} = \\displaystyle\\frac{1}{1+e^{-z}}$\n",
        "\n",
        "-   이처럼 $logit\\,function$의 역함수가 $logistic\\, function$이다.\n",
        "    따라서\n",
        "-   $logistic(z) = \\mu(z) = \\displaystyle\\frac{1}{1+e^{-z}}$\n",
        "\n",
        "`-` $logistic\\,function$의 그래프는 다음과\n",
        "같다.[(출처)](https://en.wikipedia.org/wiki/Sigmoid_function)\n",
        "\n",
        "<figure class=\"margin-caption\">\n",
        "<img\n",
        "src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/480px-Logistic-curve.svg.png\"\n",
        "alt=\"sigmoid\" />\n",
        "<figcaption aria-hidden=\"true\">sigmoid</figcaption>\n",
        "</figure>\n",
        "\n",
        "### Logistic Regression(로지스틱 회귀)\n",
        "\n",
        "`-` 그러다면 $logistic function$을 왜 사용하는 것일까?\n",
        "\n",
        "![사진](http://i.imgur.com/Co19p9c.png) [사진출처 : ratsgo’s\n",
        "blog](http://i.imgur.com/Co19p9c.png)\n",
        "\n",
        "-   나이에 따른 질병 유무에 대한 분류문제를 해결해야한다고 가정해보자.\n",
        "-   그림과 같이 분류 문제를 선형 회귀로 해결하려고 하면 그림이 많이\n",
        "    이상해집니다.\n",
        "-   따라서 앞서 언급한 $logistic\\,function$을 이용하여 문제를\n",
        "    해결합니다.\n",
        "    $logistic\\,function(z) = \\displaystyle\\frac{1}{1+e^{-z}} = \\begin{cases}1&z>\\frac12\\\\\\frac12&z=\\frac12\\\\0&z<\\frac12\\end{cases}$\n",
        "\n",
        "### 다항 로지스틱 회귀 & 소프트맥스\n",
        "\n",
        "**linear predictor**\n",
        "\n",
        "$\\begin{align}\n",
        "f(k,i) &= \\beta_{0k} + \\beta_{1k}x_{1i} + \\beta_{2k}x_{2i} + \\cdot + \\beta_{mk}x_{mi}\\\\\n",
        "       &= \\vec{\\beta_k} \\cdot \\vec{x_i}\n",
        "\\end{align}$\n",
        "\n",
        "$log(\\displaystyle\\frac{P(Y_i=k)}{P(Y_i=K)}) = \\vec{\\beta_k} \\cdot \\vec{x_i}$  \n",
        "  \n",
        "$\\Leftrightarrow \\displaystyle\\frac{P(Y_i=k)}{P(Y_i=K)} = exp(\\vec{\\beta_k} \\vec{x_i})$  \n",
        "  \n",
        "$P(Y_i=k) = P(Y_i=K)exp(\\vec{\\beta_k} \\vec{x_i})$\n",
        "\n",
        "$\\begin{align}\n",
        "P(Y_i=K) &= 1 - \\displaystyle\\sum^{j=1}_{K-1}P(Y_i = j)\\\\\n",
        "         &= 1 - \\displaystyle\\sum^{j=1}_{K-1}P(Y_i=k)exp(\\vec{\\beta_j} \\vec{x_i})\n",
        "\\end{align}$\n",
        "\n",
        "$P(Y_i=K) =  1 - \\displaystyle\\sum_{j=1}^{K-1}P(Y_i=K)exp(\\vec{\\beta_j} \\vec{x_i})$  \n",
        "  \n",
        "$P(Y_i=K)\\big(1 + \\displaystyle\\sum_{j=1}^{K-1} e^{\\vec{\\beta_j} \\vec{x_i}}\\big) = 1$  \n",
        "  \n",
        "$P(Y_i=K) = \\displaystyle\\frac{1}{1 + \\sum_{j=1}^{K-1} exp(\\vec{\\beta_j} \\vec{x_i})}$\n",
        "\n",
        "앞서서  \n",
        "$P(Y_i=k) = P(Y_i=K)exp(\\vec{\\beta_k} \\vec{x_i})$라고 했으므로  \n",
        "  \n",
        "$P(Y_i=k) = \\displaystyle\\frac{exp(\\vec{\\beta_k} \\vec{x_i})}{1 + \\sum_{j=1}^{K-1} exp(\\vec{\\beta_j} \\vec{x_i})}$\n",
        "(1)\n",
        "\n",
        "$\\displaystyle\\sum_{k=1}^{K}P(Y_i=k)=1$이 성립해야하므로 식을 다음과\n",
        "같이 작성할 수 있다.  \n",
        "$\\displaystyle\\sum_{k=1}^{K} \\displaystyle\\frac{e^{\\vec{\\beta_k} \\vec{x_i}}}{1 + \\sum_{j=1}^{K-1} e^{\\vec{\\beta_j} \\vec{x_i}}} = 1$  \n",
        "식을 정리하면  \n",
        "$\\displaystyle\\sum_{k=1}^{K}exp(\\vec{\\beta_j} \\vec{x_i}) =\\displaystyle\\sum_{j=1}^{K-1}exp(\\vec{\\beta_k} \\vec{x_i}) - 1$\n",
        "이 식을 (1)에 대입하면  \n",
        "  \n",
        "$P(Y_i=k) = \\displaystyle\\frac{exp(\\vec{\\beta_k} \\vec{x_i})}{\\sum_{k=1}^{K}exp(\\vec{\\beta_k} \\vec{x_i})}$가\n",
        "성립한다.\n",
        "\n",
        "### 로지스틱 회귀 모델 학습\n",
        "\n",
        "(추가 업로드 예정)"
      ],
      "id": "fd49ed07-81b8-4a08-8474-61e326679c6c"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  }
}