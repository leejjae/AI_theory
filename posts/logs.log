2024-03-24 23:06:09,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:06:09,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:06:09,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:06:09,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:08:39,736:INFO:PyCaret ClassificationExperiment
2024-03-24 23:08:39,736:INFO:Logging name: clf-default-name
2024-03-24 23:08:39,736:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-24 23:08:39,736:INFO:version 3.2.0
2024-03-24 23:08:39,736:INFO:Initializing setup()
2024-03-24 23:08:39,736:INFO:self.USI: 9f00
2024-03-24 23:08:39,736:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'n_jobs_param', 'X', 'exp_id', 'log_plots_param', 'is_multiclass', 'gpu_n_jobs_param', 'logging_param', 'idx', 'X_train', 'fold_generator', 'exp_name_log', '_available_plots', 'X_test', 'y', 'seed', 'y_test', 'fold_shuffle_param', 'fold_groups_param', 'html_param', 'target_param', 'pipeline', 'fix_imbalance', 'USI', 'gpu_param', 'data', 'memory'}
2024-03-24 23:08:39,736:INFO:Checking environment
2024-03-24 23:08:39,736:INFO:python_version: 3.8.19
2024-03-24 23:08:39,736:INFO:python_build: ('default', 'Mar 20 2024 19:58:24')
2024-03-24 23:08:39,736:INFO:machine: x86_64
2024-03-24 23:08:39,759:INFO:platform: Linux-5.15.0-1044-nvidia-x86_64-with-glibc2.17
2024-03-24 23:08:39,759:INFO:Memory: svmem(total=540860575744, available=470544453632, percent=13.0, used=66753531904, free=111974338560, active=130977673216, inactive=269501521920, buffers=9814007808, cached=352318697472, shared=41619456, slab=25423101952)
2024-03-24 23:08:39,763:INFO:Physical Core: 64
2024-03-24 23:08:39,763:INFO:Logical Core: 128
2024-03-24 23:08:39,763:INFO:Checking libraries
2024-03-24 23:08:39,763:INFO:System:
2024-03-24 23:08:39,763:INFO:    python: 3.8.19 (default, Mar 20 2024, 19:58:24)  [GCC 11.2.0]
2024-03-24 23:08:39,763:INFO:executable: /root/anaconda3/envs/pc/bin/python
2024-03-24 23:08:39,763:INFO:   machine: Linux-5.15.0-1044-nvidia-x86_64-with-glibc2.17
2024-03-24 23:08:39,763:INFO:PyCaret required dependencies:
2024-03-24 23:08:39,765:INFO:                 pip: 23.3.1
2024-03-24 23:08:39,765:INFO:          setuptools: 68.2.2
2024-03-24 23:08:39,765:INFO:             pycaret: 3.2.0
2024-03-24 23:08:39,765:INFO:             IPython: 8.12.0
2024-03-24 23:08:39,765:INFO:          ipywidgets: 8.1.2
2024-03-24 23:08:39,765:INFO:                tqdm: 4.66.2
2024-03-24 23:08:39,765:INFO:               numpy: 1.24.4
2024-03-24 23:08:39,765:INFO:              pandas: 1.5.3
2024-03-24 23:08:39,765:INFO:              jinja2: 3.1.3
2024-03-24 23:08:39,765:INFO:               scipy: 1.10.1
2024-03-24 23:08:39,765:INFO:              joblib: 1.3.2
2024-03-24 23:08:39,765:INFO:             sklearn: 1.2.2
2024-03-24 23:08:39,765:INFO:                pyod: 1.1.3
2024-03-24 23:08:39,765:INFO:            imblearn: 0.12.0
2024-03-24 23:08:39,765:INFO:   category_encoders: 2.6.3
2024-03-24 23:08:39,765:INFO:            lightgbm: 4.3.0
2024-03-24 23:08:39,765:INFO:               numba: 0.58.1
2024-03-24 23:08:39,765:INFO:            requests: 2.31.0
2024-03-24 23:08:39,765:INFO:          matplotlib: 3.6.0
2024-03-24 23:08:39,765:INFO:          scikitplot: 0.3.7
2024-03-24 23:08:39,765:INFO:         yellowbrick: 1.5
2024-03-24 23:08:39,765:INFO:              plotly: 5.20.0
2024-03-24 23:08:39,765:INFO:    plotly-resampler: Not installed
2024-03-24 23:08:39,765:INFO:             kaleido: 0.2.1
2024-03-24 23:08:39,765:INFO:           schemdraw: 0.15
2024-03-24 23:08:39,765:INFO:         statsmodels: 0.14.1
2024-03-24 23:08:39,765:INFO:              sktime: 0.21.1
2024-03-24 23:08:39,765:INFO:               tbats: 1.1.3
2024-03-24 23:08:39,765:INFO:            pmdarima: 2.0.4
2024-03-24 23:08:39,765:INFO:              psutil: 5.9.8
2024-03-24 23:08:39,765:INFO:          markupsafe: 2.1.3
2024-03-24 23:08:39,765:INFO:             pickle5: Not installed
2024-03-24 23:08:39,765:INFO:         cloudpickle: 3.0.0
2024-03-24 23:08:39,765:INFO:         deprecation: 2.1.0
2024-03-24 23:08:39,765:INFO:              xxhash: 3.4.1
2024-03-24 23:08:39,765:INFO:           wurlitzer: 3.0.3
2024-03-24 23:08:39,765:INFO:PyCaret optional dependencies:
2024-03-24 23:08:39,780:INFO:                shap: Not installed
2024-03-24 23:08:39,780:INFO:           interpret: Not installed
2024-03-24 23:08:39,780:INFO:                umap: Not installed
2024-03-24 23:08:39,780:INFO:     ydata_profiling: Not installed
2024-03-24 23:08:39,780:INFO:  explainerdashboard: Not installed
2024-03-24 23:08:39,780:INFO:             autoviz: Not installed
2024-03-24 23:08:39,780:INFO:           fairlearn: Not installed
2024-03-24 23:08:39,780:INFO:          deepchecks: Not installed
2024-03-24 23:08:39,780:INFO:             xgboost: Not installed
2024-03-24 23:08:39,780:INFO:            catboost: Not installed
2024-03-24 23:08:39,780:INFO:              kmodes: Not installed
2024-03-24 23:08:39,780:INFO:             mlxtend: Not installed
2024-03-24 23:08:39,780:INFO:       statsforecast: Not installed
2024-03-24 23:08:39,780:INFO:        tune_sklearn: Not installed
2024-03-24 23:08:39,780:INFO:                 ray: Not installed
2024-03-24 23:08:39,780:INFO:            hyperopt: Not installed
2024-03-24 23:08:39,780:INFO:              optuna: Not installed
2024-03-24 23:08:39,780:INFO:               skopt: Not installed
2024-03-24 23:08:39,780:INFO:              mlflow: Not installed
2024-03-24 23:08:39,780:INFO:              gradio: Not installed
2024-03-24 23:08:39,780:INFO:             fastapi: Not installed
2024-03-24 23:08:39,780:INFO:             uvicorn: Not installed
2024-03-24 23:08:39,780:INFO:              m2cgen: Not installed
2024-03-24 23:08:39,780:INFO:           evidently: Not installed
2024-03-24 23:08:39,780:INFO:               fugue: Not installed
2024-03-24 23:08:39,780:INFO:           streamlit: Not installed
2024-03-24 23:08:39,780:INFO:             prophet: Not installed
2024-03-24 23:08:39,780:INFO:None
2024-03-24 23:08:39,780:INFO:Set up data.
2024-03-24 23:08:39,784:INFO:Set up folding strategy.
2024-03-24 23:08:39,784:INFO:Set up train/test split.
2024-03-24 23:08:39,787:INFO:Set up index.
2024-03-24 23:08:39,787:INFO:Assigning column types.
2024-03-24 23:08:39,790:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-24 23:08:39,837:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-24 23:08:39,838:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-24 23:08:39,869:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:08:39,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:08:39,917:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-24 23:08:39,918:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-24 23:08:39,947:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:08:39,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:08:39,947:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-24 23:08:39,994:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-24 23:08:40,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:08:40,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:08:40,071:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-24 23:08:40,099:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:08:40,100:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:08:40,100:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-24 23:08:40,176:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:08:40,176:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:08:40,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:08:40,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:08:40,252:INFO:Preparing preprocessing pipeline...
2024-03-24 23:08:40,252:INFO:Set up simple imputation.
2024-03-24 23:08:40,265:INFO:Finished creating preprocessing pipeline.
2024-03-24 23:08:40,269:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'SibSp', 'Age', 'Sex'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2024-03-24 23:08:40,269:INFO:Creating final display dataframe.
2024-03-24 23:08:40,314:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 5)
4        Transformed data shape          (891, 5)
5   Transformed train set shape          (623, 5)
6    Transformed test set shape          (268, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              9f00
2024-03-24 23:08:40,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:08:40,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:08:40,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:08:40,473:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:08:40,474:INFO:setup() successfully completed in 0.74s...............
2024-03-24 23:08:40,474:INFO:Initializing compare_models()
2024-03-24 23:08:40,474:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbba1210c10>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fbba1210c10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-03-24 23:08:40,474:INFO:Checking exceptions
2024-03-24 23:08:40,476:INFO:Preparing display monitor
2024-03-24 23:08:40,496:INFO:Initializing Logistic Regression
2024-03-24 23:08:40,496:INFO:Total runtime is 2.9087066650390623e-06 minutes
2024-03-24 23:08:40,498:INFO:SubProcess create_model() called ==================================
2024-03-24 23:08:40,498:INFO:Initializing create_model()
2024-03-24 23:08:40,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbba1210c10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc4cd08280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:08:40,499:INFO:Checking exceptions
2024-03-24 23:08:40,499:INFO:Importing libraries
2024-03-24 23:08:40,499:INFO:Copying training dataset
2024-03-24 23:08:40,501:INFO:Defining folds
2024-03-24 23:08:40,501:INFO:Declaring metric variables
2024-03-24 23:08:40,504:INFO:Importing untrained model
2024-03-24 23:08:40,507:INFO:Logistic Regression Imported successfully
2024-03-24 23:08:40,512:INFO:Starting cross validation
2024-03-24 23:08:40,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:08:42,908:INFO:Calculating mean and std
2024-03-24 23:08:42,910:INFO:Creating metrics dataframe
2024-03-24 23:08:42,914:INFO:Uploading results into container
2024-03-24 23:08:42,915:INFO:Uploading model into container now
2024-03-24 23:08:42,915:INFO:_master_model_container: 1
2024-03-24 23:08:42,915:INFO:_display_container: 2
2024-03-24 23:08:42,915:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-03-24 23:08:42,915:INFO:create_model() successfully completed......................................
2024-03-24 23:08:43,003:INFO:SubProcess create_model() end ==================================
2024-03-24 23:08:43,003:INFO:Creating metrics dataframe
2024-03-24 23:08:43,011:INFO:Initializing K Neighbors Classifier
2024-03-24 23:08:43,012:INFO:Total runtime is 0.04193285703659058 minutes
2024-03-24 23:08:43,014:INFO:SubProcess create_model() called ==================================
2024-03-24 23:08:43,015:INFO:Initializing create_model()
2024-03-24 23:08:43,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbba1210c10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc4cd08280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:08:43,015:INFO:Checking exceptions
2024-03-24 23:08:43,015:INFO:Importing libraries
2024-03-24 23:08:43,015:INFO:Copying training dataset
2024-03-24 23:08:43,018:INFO:Defining folds
2024-03-24 23:08:43,018:INFO:Declaring metric variables
2024-03-24 23:08:43,021:INFO:Importing untrained model
2024-03-24 23:08:43,023:INFO:K Neighbors Classifier Imported successfully
2024-03-24 23:08:43,028:INFO:Starting cross validation
2024-03-24 23:08:43,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:08:44,217:INFO:Calculating mean and std
2024-03-24 23:08:44,218:INFO:Creating metrics dataframe
2024-03-24 23:08:44,221:INFO:Uploading results into container
2024-03-24 23:08:44,222:INFO:Uploading model into container now
2024-03-24 23:08:44,222:INFO:_master_model_container: 2
2024-03-24 23:08:44,222:INFO:_display_container: 2
2024-03-24 23:08:44,223:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-03-24 23:08:44,223:INFO:create_model() successfully completed......................................
2024-03-24 23:08:44,309:INFO:SubProcess create_model() end ==================================
2024-03-24 23:08:44,309:INFO:Creating metrics dataframe
2024-03-24 23:08:44,318:INFO:Initializing Naive Bayes
2024-03-24 23:08:44,318:INFO:Total runtime is 0.0637123982111613 minutes
2024-03-24 23:08:44,321:INFO:SubProcess create_model() called ==================================
2024-03-24 23:08:44,321:INFO:Initializing create_model()
2024-03-24 23:08:44,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbba1210c10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc4cd08280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:08:44,321:INFO:Checking exceptions
2024-03-24 23:08:44,322:INFO:Importing libraries
2024-03-24 23:08:44,322:INFO:Copying training dataset
2024-03-24 23:08:44,325:INFO:Defining folds
2024-03-24 23:08:44,325:INFO:Declaring metric variables
2024-03-24 23:08:44,328:INFO:Importing untrained model
2024-03-24 23:08:44,330:INFO:Naive Bayes Imported successfully
2024-03-24 23:08:44,336:INFO:Starting cross validation
2024-03-24 23:08:44,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:08:45,464:INFO:Calculating mean and std
2024-03-24 23:08:45,465:INFO:Creating metrics dataframe
2024-03-24 23:08:45,468:INFO:Uploading results into container
2024-03-24 23:08:45,469:INFO:Uploading model into container now
2024-03-24 23:08:45,469:INFO:_master_model_container: 3
2024-03-24 23:08:45,469:INFO:_display_container: 2
2024-03-24 23:08:45,469:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-03-24 23:08:45,469:INFO:create_model() successfully completed......................................
2024-03-24 23:08:45,551:INFO:SubProcess create_model() end ==================================
2024-03-24 23:08:45,551:INFO:Creating metrics dataframe
2024-03-24 23:08:45,560:INFO:Initializing Decision Tree Classifier
2024-03-24 23:08:45,560:INFO:Total runtime is 0.08440794150034586 minutes
2024-03-24 23:08:45,563:INFO:SubProcess create_model() called ==================================
2024-03-24 23:08:45,563:INFO:Initializing create_model()
2024-03-24 23:08:45,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbba1210c10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc4cd08280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:08:45,563:INFO:Checking exceptions
2024-03-24 23:08:45,563:INFO:Importing libraries
2024-03-24 23:08:45,563:INFO:Copying training dataset
2024-03-24 23:08:45,566:INFO:Defining folds
2024-03-24 23:08:45,566:INFO:Declaring metric variables
2024-03-24 23:08:45,569:INFO:Importing untrained model
2024-03-24 23:08:45,572:INFO:Decision Tree Classifier Imported successfully
2024-03-24 23:08:45,577:INFO:Starting cross validation
2024-03-24 23:08:45,578:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:08:46,667:INFO:Calculating mean and std
2024-03-24 23:08:46,668:INFO:Creating metrics dataframe
2024-03-24 23:08:46,672:INFO:Uploading results into container
2024-03-24 23:08:46,672:INFO:Uploading model into container now
2024-03-24 23:08:46,672:INFO:_master_model_container: 4
2024-03-24 23:08:46,672:INFO:_display_container: 2
2024-03-24 23:08:46,673:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-03-24 23:08:46,673:INFO:create_model() successfully completed......................................
2024-03-24 23:08:46,748:INFO:SubProcess create_model() end ==================================
2024-03-24 23:08:46,748:INFO:Creating metrics dataframe
2024-03-24 23:08:46,757:INFO:Initializing SVM - Linear Kernel
2024-03-24 23:08:46,758:INFO:Total runtime is 0.10436784029006957 minutes
2024-03-24 23:08:46,760:INFO:SubProcess create_model() called ==================================
2024-03-24 23:08:46,761:INFO:Initializing create_model()
2024-03-24 23:08:46,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbba1210c10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc4cd08280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:08:46,761:INFO:Checking exceptions
2024-03-24 23:08:46,761:INFO:Importing libraries
2024-03-24 23:08:46,761:INFO:Copying training dataset
2024-03-24 23:08:46,763:INFO:Defining folds
2024-03-24 23:08:46,763:INFO:Declaring metric variables
2024-03-24 23:08:46,766:INFO:Importing untrained model
2024-03-24 23:08:46,769:INFO:SVM - Linear Kernel Imported successfully
2024-03-24 23:08:46,775:INFO:Starting cross validation
2024-03-24 23:08:46,775:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:08:47,773:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:08:47,793:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:08:47,811:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:08:47,835:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:08:47,835:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:08:47,844:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:08:47,878:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:08:47,885:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:08:47,894:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:08:47,900:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:08:47,914:INFO:Calculating mean and std
2024-03-24 23:08:47,915:INFO:Creating metrics dataframe
2024-03-24 23:08:47,918:INFO:Uploading results into container
2024-03-24 23:08:47,919:INFO:Uploading model into container now
2024-03-24 23:08:47,919:INFO:_master_model_container: 5
2024-03-24 23:08:47,919:INFO:_display_container: 2
2024-03-24 23:08:47,920:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-03-24 23:08:47,920:INFO:create_model() successfully completed......................................
2024-03-24 23:08:48,000:INFO:SubProcess create_model() end ==================================
2024-03-24 23:08:48,000:INFO:Creating metrics dataframe
2024-03-24 23:08:48,010:INFO:Initializing Ridge Classifier
2024-03-24 23:08:48,010:INFO:Total runtime is 0.12524050871531167 minutes
2024-03-24 23:08:48,013:INFO:SubProcess create_model() called ==================================
2024-03-24 23:08:48,013:INFO:Initializing create_model()
2024-03-24 23:08:48,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbba1210c10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc4cd08280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:08:48,013:INFO:Checking exceptions
2024-03-24 23:08:48,013:INFO:Importing libraries
2024-03-24 23:08:48,013:INFO:Copying training dataset
2024-03-24 23:08:48,016:INFO:Defining folds
2024-03-24 23:08:48,016:INFO:Declaring metric variables
2024-03-24 23:08:48,018:INFO:Importing untrained model
2024-03-24 23:08:48,021:INFO:Ridge Classifier Imported successfully
2024-03-24 23:08:48,027:INFO:Starting cross validation
2024-03-24 23:08:48,027:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:08:49,006:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:08:49,009:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:08:49,024:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:08:49,025:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:08:49,025:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:08:49,027:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:08:49,029:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:08:49,029:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:08:49,043:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:08:49,046:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:08:49,064:INFO:Calculating mean and std
2024-03-24 23:08:49,065:INFO:Creating metrics dataframe
2024-03-24 23:08:49,069:INFO:Uploading results into container
2024-03-24 23:08:49,069:INFO:Uploading model into container now
2024-03-24 23:08:49,069:INFO:_master_model_container: 6
2024-03-24 23:08:49,070:INFO:_display_container: 2
2024-03-24 23:08:49,070:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-03-24 23:08:49,070:INFO:create_model() successfully completed......................................
2024-03-24 23:08:49,147:INFO:SubProcess create_model() end ==================================
2024-03-24 23:08:49,147:INFO:Creating metrics dataframe
2024-03-24 23:08:49,157:INFO:Initializing Random Forest Classifier
2024-03-24 23:08:49,157:INFO:Total runtime is 0.14436107476552326 minutes
2024-03-24 23:08:49,160:INFO:SubProcess create_model() called ==================================
2024-03-24 23:08:49,160:INFO:Initializing create_model()
2024-03-24 23:08:49,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbba1210c10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc4cd08280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:08:49,160:INFO:Checking exceptions
2024-03-24 23:08:49,160:INFO:Importing libraries
2024-03-24 23:08:49,160:INFO:Copying training dataset
2024-03-24 23:08:49,163:INFO:Defining folds
2024-03-24 23:08:49,163:INFO:Declaring metric variables
2024-03-24 23:08:49,165:INFO:Importing untrained model
2024-03-24 23:08:49,168:INFO:Random Forest Classifier Imported successfully
2024-03-24 23:08:49,174:INFO:Starting cross validation
2024-03-24 23:08:49,175:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:08:50,483:INFO:Calculating mean and std
2024-03-24 23:08:50,484:INFO:Creating metrics dataframe
2024-03-24 23:08:50,488:INFO:Uploading results into container
2024-03-24 23:08:50,488:INFO:Uploading model into container now
2024-03-24 23:08:50,489:INFO:_master_model_container: 7
2024-03-24 23:08:50,489:INFO:_display_container: 2
2024-03-24 23:08:50,489:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-03-24 23:08:50,489:INFO:create_model() successfully completed......................................
2024-03-24 23:08:50,566:INFO:SubProcess create_model() end ==================================
2024-03-24 23:08:50,566:INFO:Creating metrics dataframe
2024-03-24 23:08:50,576:INFO:Initializing Quadratic Discriminant Analysis
2024-03-24 23:08:50,576:INFO:Total runtime is 0.16801311175028483 minutes
2024-03-24 23:08:50,579:INFO:SubProcess create_model() called ==================================
2024-03-24 23:08:50,579:INFO:Initializing create_model()
2024-03-24 23:08:50,579:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbba1210c10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc4cd08280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:08:50,580:INFO:Checking exceptions
2024-03-24 23:08:50,580:INFO:Importing libraries
2024-03-24 23:08:50,580:INFO:Copying training dataset
2024-03-24 23:08:50,582:INFO:Defining folds
2024-03-24 23:08:50,582:INFO:Declaring metric variables
2024-03-24 23:08:50,585:INFO:Importing untrained model
2024-03-24 23:08:50,588:INFO:Quadratic Discriminant Analysis Imported successfully
2024-03-24 23:08:50,594:INFO:Starting cross validation
2024-03-24 23:08:50,595:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:08:51,631:INFO:Calculating mean and std
2024-03-24 23:08:51,632:INFO:Creating metrics dataframe
2024-03-24 23:08:51,635:INFO:Uploading results into container
2024-03-24 23:08:51,636:INFO:Uploading model into container now
2024-03-24 23:08:51,637:INFO:_master_model_container: 8
2024-03-24 23:08:51,637:INFO:_display_container: 2
2024-03-24 23:08:51,637:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-03-24 23:08:51,637:INFO:create_model() successfully completed......................................
2024-03-24 23:08:51,714:INFO:SubProcess create_model() end ==================================
2024-03-24 23:08:51,714:INFO:Creating metrics dataframe
2024-03-24 23:08:51,724:INFO:Initializing Ada Boost Classifier
2024-03-24 23:08:51,725:INFO:Total runtime is 0.187149707476298 minutes
2024-03-24 23:08:51,727:INFO:SubProcess create_model() called ==================================
2024-03-24 23:08:51,728:INFO:Initializing create_model()
2024-03-24 23:08:51,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbba1210c10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc4cd08280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:08:51,728:INFO:Checking exceptions
2024-03-24 23:08:51,728:INFO:Importing libraries
2024-03-24 23:08:51,728:INFO:Copying training dataset
2024-03-24 23:08:51,730:INFO:Defining folds
2024-03-24 23:08:51,730:INFO:Declaring metric variables
2024-03-24 23:08:51,733:INFO:Importing untrained model
2024-03-24 23:08:51,736:INFO:Ada Boost Classifier Imported successfully
2024-03-24 23:08:51,741:INFO:Starting cross validation
2024-03-24 23:08:51,742:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:08:52,829:INFO:Calculating mean and std
2024-03-24 23:08:52,830:INFO:Creating metrics dataframe
2024-03-24 23:08:52,833:INFO:Uploading results into container
2024-03-24 23:08:52,834:INFO:Uploading model into container now
2024-03-24 23:08:52,834:INFO:_master_model_container: 9
2024-03-24 23:08:52,834:INFO:_display_container: 2
2024-03-24 23:08:52,834:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-03-24 23:08:52,835:INFO:create_model() successfully completed......................................
2024-03-24 23:08:52,912:INFO:SubProcess create_model() end ==================================
2024-03-24 23:08:52,912:INFO:Creating metrics dataframe
2024-03-24 23:08:52,923:INFO:Initializing Gradient Boosting Classifier
2024-03-24 23:08:52,923:INFO:Total runtime is 0.20712676843007405 minutes
2024-03-24 23:08:52,926:INFO:SubProcess create_model() called ==================================
2024-03-24 23:08:52,926:INFO:Initializing create_model()
2024-03-24 23:08:52,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbba1210c10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc4cd08280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:08:52,926:INFO:Checking exceptions
2024-03-24 23:08:52,927:INFO:Importing libraries
2024-03-24 23:08:52,927:INFO:Copying training dataset
2024-03-24 23:08:52,929:INFO:Defining folds
2024-03-24 23:08:52,929:INFO:Declaring metric variables
2024-03-24 23:08:52,932:INFO:Importing untrained model
2024-03-24 23:08:52,935:INFO:Gradient Boosting Classifier Imported successfully
2024-03-24 23:08:52,940:INFO:Starting cross validation
2024-03-24 23:08:52,941:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:08:54,050:INFO:Calculating mean and std
2024-03-24 23:08:54,051:INFO:Creating metrics dataframe
2024-03-24 23:08:54,054:INFO:Uploading results into container
2024-03-24 23:08:54,055:INFO:Uploading model into container now
2024-03-24 23:08:54,055:INFO:_master_model_container: 10
2024-03-24 23:08:54,055:INFO:_display_container: 2
2024-03-24 23:08:54,056:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-24 23:08:54,056:INFO:create_model() successfully completed......................................
2024-03-24 23:08:54,133:INFO:SubProcess create_model() end ==================================
2024-03-24 23:08:54,133:INFO:Creating metrics dataframe
2024-03-24 23:08:54,144:INFO:Initializing Linear Discriminant Analysis
2024-03-24 23:08:54,144:INFO:Total runtime is 0.22747684717178343 minutes
2024-03-24 23:08:54,147:INFO:SubProcess create_model() called ==================================
2024-03-24 23:08:54,147:INFO:Initializing create_model()
2024-03-24 23:08:54,147:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbba1210c10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc4cd08280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:08:54,147:INFO:Checking exceptions
2024-03-24 23:08:54,147:INFO:Importing libraries
2024-03-24 23:08:54,147:INFO:Copying training dataset
2024-03-24 23:08:54,150:INFO:Defining folds
2024-03-24 23:08:54,150:INFO:Declaring metric variables
2024-03-24 23:08:54,152:INFO:Importing untrained model
2024-03-24 23:08:54,155:INFO:Linear Discriminant Analysis Imported successfully
2024-03-24 23:08:54,161:INFO:Starting cross validation
2024-03-24 23:08:54,162:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:08:55,188:INFO:Calculating mean and std
2024-03-24 23:08:55,189:INFO:Creating metrics dataframe
2024-03-24 23:08:55,192:INFO:Uploading results into container
2024-03-24 23:08:55,192:INFO:Uploading model into container now
2024-03-24 23:08:55,193:INFO:_master_model_container: 11
2024-03-24 23:08:55,193:INFO:_display_container: 2
2024-03-24 23:08:55,193:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-03-24 23:08:55,193:INFO:create_model() successfully completed......................................
2024-03-24 23:08:55,270:INFO:SubProcess create_model() end ==================================
2024-03-24 23:08:55,270:INFO:Creating metrics dataframe
2024-03-24 23:08:55,281:INFO:Initializing Extra Trees Classifier
2024-03-24 23:08:55,281:INFO:Total runtime is 0.2464309255282084 minutes
2024-03-24 23:08:55,284:INFO:SubProcess create_model() called ==================================
2024-03-24 23:08:55,284:INFO:Initializing create_model()
2024-03-24 23:08:55,284:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbba1210c10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc4cd08280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:08:55,284:INFO:Checking exceptions
2024-03-24 23:08:55,284:INFO:Importing libraries
2024-03-24 23:08:55,284:INFO:Copying training dataset
2024-03-24 23:08:55,287:INFO:Defining folds
2024-03-24 23:08:55,287:INFO:Declaring metric variables
2024-03-24 23:08:55,290:INFO:Importing untrained model
2024-03-24 23:08:55,292:INFO:Extra Trees Classifier Imported successfully
2024-03-24 23:08:55,298:INFO:Starting cross validation
2024-03-24 23:08:55,299:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:08:56,557:INFO:Calculating mean and std
2024-03-24 23:08:56,558:INFO:Creating metrics dataframe
2024-03-24 23:08:56,562:INFO:Uploading results into container
2024-03-24 23:08:56,562:INFO:Uploading model into container now
2024-03-24 23:08:56,563:INFO:_master_model_container: 12
2024-03-24 23:08:56,563:INFO:_display_container: 2
2024-03-24 23:08:56,563:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-03-24 23:08:56,563:INFO:create_model() successfully completed......................................
2024-03-24 23:08:56,643:INFO:SubProcess create_model() end ==================================
2024-03-24 23:08:56,643:INFO:Creating metrics dataframe
2024-03-24 23:08:56,654:INFO:Initializing Light Gradient Boosting Machine
2024-03-24 23:08:56,654:INFO:Total runtime is 0.26931091944376623 minutes
2024-03-24 23:08:56,657:INFO:SubProcess create_model() called ==================================
2024-03-24 23:08:56,657:INFO:Initializing create_model()
2024-03-24 23:08:56,657:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbba1210c10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbc4cd08280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:08:56,657:INFO:Checking exceptions
2024-03-24 23:08:56,657:INFO:Importing libraries
2024-03-24 23:08:56,657:INFO:Copying training dataset
2024-03-24 23:08:56,660:INFO:Defining folds
2024-03-24 23:08:56,660:INFO:Declaring metric variables
2024-03-24 23:08:56,663:INFO:Importing untrained model
2024-03-24 23:08:56,666:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-24 23:08:56,672:INFO:Starting cross validation
2024-03-24 23:08:56,672:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:13:02,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:13:02,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:13:02,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:13:02,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:13:02,729:INFO:PyCaret ClassificationExperiment
2024-03-24 23:13:02,729:INFO:Logging name: clf-default-name
2024-03-24 23:13:02,729:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-24 23:13:02,729:INFO:version 3.2.0
2024-03-24 23:13:02,729:INFO:Initializing setup()
2024-03-24 23:13:02,729:INFO:self.USI: 3d5a
2024-03-24 23:13:02,730:INFO:self._variable_keys: {'is_multiclass', 'fix_imbalance', 'fold_shuffle_param', 'fold_groups_param', 'html_param', 'exp_name_log', 'X_test', 'n_jobs_param', 'gpu_n_jobs_param', 'X_train', 'X', 'idx', 'target_param', 'logging_param', 'pipeline', 'memory', 'y_train', 'seed', 'log_plots_param', '_available_plots', 'exp_id', 'gpu_param', 'y', 'data', 'y_test', 'fold_generator', 'USI', '_ml_usecase'}
2024-03-24 23:13:02,730:INFO:Checking environment
2024-03-24 23:13:02,730:INFO:python_version: 3.8.19
2024-03-24 23:13:02,730:INFO:python_build: ('default', 'Mar 20 2024 19:58:24')
2024-03-24 23:13:02,730:INFO:machine: x86_64
2024-03-24 23:13:02,752:INFO:platform: Linux-5.15.0-1044-nvidia-x86_64-with-glibc2.17
2024-03-24 23:13:02,752:INFO:Memory: svmem(total=540860575744, available=470137683968, percent=13.1, used=67160276992, free=111564509184, active=130979041280, inactive=269532254208, buffers=9814007808, cached=352321781760, shared=41619456, slab=25454153728)
2024-03-24 23:13:02,756:INFO:Physical Core: 64
2024-03-24 23:13:02,756:INFO:Logical Core: 128
2024-03-24 23:13:02,756:INFO:Checking libraries
2024-03-24 23:13:02,756:INFO:System:
2024-03-24 23:13:02,756:INFO:    python: 3.8.19 (default, Mar 20 2024, 19:58:24)  [GCC 11.2.0]
2024-03-24 23:13:02,756:INFO:executable: /root/anaconda3/envs/pc/bin/python
2024-03-24 23:13:02,756:INFO:   machine: Linux-5.15.0-1044-nvidia-x86_64-with-glibc2.17
2024-03-24 23:13:02,756:INFO:PyCaret required dependencies:
2024-03-24 23:13:02,774:INFO:                 pip: 23.3.1
2024-03-24 23:13:02,774:INFO:          setuptools: 68.2.2
2024-03-24 23:13:02,774:INFO:             pycaret: 3.2.0
2024-03-24 23:13:02,774:INFO:             IPython: 8.12.0
2024-03-24 23:13:02,774:INFO:          ipywidgets: 8.1.2
2024-03-24 23:13:02,774:INFO:                tqdm: 4.66.2
2024-03-24 23:13:02,774:INFO:               numpy: 1.24.4
2024-03-24 23:13:02,774:INFO:              pandas: 1.5.3
2024-03-24 23:13:02,774:INFO:              jinja2: 3.1.3
2024-03-24 23:13:02,774:INFO:               scipy: 1.10.1
2024-03-24 23:13:02,774:INFO:              joblib: 1.3.2
2024-03-24 23:13:02,774:INFO:             sklearn: 1.2.2
2024-03-24 23:13:02,774:INFO:                pyod: 1.1.3
2024-03-24 23:13:02,774:INFO:            imblearn: 0.12.0
2024-03-24 23:13:02,774:INFO:   category_encoders: 2.6.3
2024-03-24 23:13:02,774:INFO:            lightgbm: 4.3.0
2024-03-24 23:13:02,774:INFO:               numba: 0.58.1
2024-03-24 23:13:02,774:INFO:            requests: 2.31.0
2024-03-24 23:13:02,774:INFO:          matplotlib: 3.6.0
2024-03-24 23:13:02,774:INFO:          scikitplot: 0.3.7
2024-03-24 23:13:02,774:INFO:         yellowbrick: 1.5
2024-03-24 23:13:02,774:INFO:              plotly: 5.20.0
2024-03-24 23:13:02,774:INFO:    plotly-resampler: Not installed
2024-03-24 23:13:02,774:INFO:             kaleido: 0.2.1
2024-03-24 23:13:02,774:INFO:           schemdraw: 0.15
2024-03-24 23:13:02,774:INFO:         statsmodels: 0.14.1
2024-03-24 23:13:02,774:INFO:              sktime: 0.21.1
2024-03-24 23:13:02,774:INFO:               tbats: 1.1.3
2024-03-24 23:13:02,774:INFO:            pmdarima: 2.0.4
2024-03-24 23:13:02,774:INFO:              psutil: 5.9.8
2024-03-24 23:13:02,774:INFO:          markupsafe: 2.1.3
2024-03-24 23:13:02,774:INFO:             pickle5: Not installed
2024-03-24 23:13:02,774:INFO:         cloudpickle: 3.0.0
2024-03-24 23:13:02,774:INFO:         deprecation: 2.1.0
2024-03-24 23:13:02,774:INFO:              xxhash: 3.4.1
2024-03-24 23:13:02,775:INFO:           wurlitzer: 3.0.3
2024-03-24 23:13:02,775:INFO:PyCaret optional dependencies:
2024-03-24 23:13:02,789:INFO:                shap: Not installed
2024-03-24 23:13:02,789:INFO:           interpret: Not installed
2024-03-24 23:13:02,789:INFO:                umap: Not installed
2024-03-24 23:13:02,789:INFO:     ydata_profiling: Not installed
2024-03-24 23:13:02,789:INFO:  explainerdashboard: Not installed
2024-03-24 23:13:02,789:INFO:             autoviz: Not installed
2024-03-24 23:13:02,789:INFO:           fairlearn: Not installed
2024-03-24 23:13:02,789:INFO:          deepchecks: Not installed
2024-03-24 23:13:02,789:INFO:             xgboost: Not installed
2024-03-24 23:13:02,789:INFO:            catboost: Not installed
2024-03-24 23:13:02,789:INFO:              kmodes: Not installed
2024-03-24 23:13:02,789:INFO:             mlxtend: Not installed
2024-03-24 23:13:02,789:INFO:       statsforecast: Not installed
2024-03-24 23:13:02,789:INFO:        tune_sklearn: Not installed
2024-03-24 23:13:02,789:INFO:                 ray: Not installed
2024-03-24 23:13:02,789:INFO:            hyperopt: Not installed
2024-03-24 23:13:02,789:INFO:              optuna: Not installed
2024-03-24 23:13:02,789:INFO:               skopt: Not installed
2024-03-24 23:13:02,789:INFO:              mlflow: Not installed
2024-03-24 23:13:02,789:INFO:              gradio: Not installed
2024-03-24 23:13:02,789:INFO:             fastapi: Not installed
2024-03-24 23:13:02,789:INFO:             uvicorn: Not installed
2024-03-24 23:13:02,789:INFO:              m2cgen: Not installed
2024-03-24 23:13:02,789:INFO:           evidently: Not installed
2024-03-24 23:13:02,789:INFO:               fugue: Not installed
2024-03-24 23:13:02,789:INFO:           streamlit: Not installed
2024-03-24 23:13:02,789:INFO:             prophet: Not installed
2024-03-24 23:13:02,789:INFO:None
2024-03-24 23:13:02,789:INFO:Set up data.
2024-03-24 23:13:02,793:INFO:Set up folding strategy.
2024-03-24 23:13:02,793:INFO:Set up train/test split.
2024-03-24 23:13:02,796:INFO:Set up index.
2024-03-24 23:13:02,796:INFO:Assigning column types.
2024-03-24 23:13:02,799:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-24 23:13:02,846:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-24 23:13:02,847:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-24 23:13:02,877:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:13:02,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:13:02,924:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-24 23:13:02,924:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-24 23:13:02,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:13:02,953:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:13:02,953:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-24 23:13:03,000:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-24 23:13:03,029:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:13:03,029:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:13:03,076:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-24 23:13:03,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:13:03,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:13:03,105:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-24 23:13:03,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:13:03,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:13:03,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:13:03,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:13:03,257:INFO:Preparing preprocessing pipeline...
2024-03-24 23:13:03,258:INFO:Set up simple imputation.
2024-03-24 23:13:03,271:INFO:Finished creating preprocessing pipeline.
2024-03-24 23:13:03,275:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'SibSp', 'Age', 'Sex'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2024-03-24 23:13:03,275:INFO:Creating final display dataframe.
2024-03-24 23:13:03,319:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 5)
4        Transformed data shape          (891, 5)
5   Transformed train set shape          (623, 5)
6    Transformed test set shape          (268, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3d5a
2024-03-24 23:13:03,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:13:03,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:13:03,480:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:13:03,481:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:13:03,481:INFO:setup() successfully completed in 0.75s...............
2024-03-24 23:13:03,481:INFO:Initializing compare_models()
2024-03-24 23:13:03,481:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbe243af220>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fbe243af220>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-03-24 23:13:03,481:INFO:Checking exceptions
2024-03-24 23:13:03,483:INFO:Preparing display monitor
2024-03-24 23:13:03,504:INFO:Initializing Logistic Regression
2024-03-24 23:13:03,504:INFO:Total runtime is 2.797444661458333e-06 minutes
2024-03-24 23:13:03,506:INFO:SubProcess create_model() called ==================================
2024-03-24 23:13:03,507:INFO:Initializing create_model()
2024-03-24 23:13:03,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbe243af220>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbcbc0503a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:13:03,507:INFO:Checking exceptions
2024-03-24 23:13:03,507:INFO:Importing libraries
2024-03-24 23:13:03,507:INFO:Copying training dataset
2024-03-24 23:13:03,509:INFO:Defining folds
2024-03-24 23:13:03,509:INFO:Declaring metric variables
2024-03-24 23:13:03,512:INFO:Importing untrained model
2024-03-24 23:13:03,515:INFO:Logistic Regression Imported successfully
2024-03-24 23:13:03,520:INFO:Starting cross validation
2024-03-24 23:13:03,520:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:13:05,899:INFO:Calculating mean and std
2024-03-24 23:13:05,901:INFO:Creating metrics dataframe
2024-03-24 23:13:05,905:INFO:Uploading results into container
2024-03-24 23:13:05,905:INFO:Uploading model into container now
2024-03-24 23:13:05,906:INFO:_master_model_container: 1
2024-03-24 23:13:05,906:INFO:_display_container: 2
2024-03-24 23:13:05,906:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-03-24 23:13:05,907:INFO:create_model() successfully completed......................................
2024-03-24 23:13:05,979:INFO:SubProcess create_model() end ==================================
2024-03-24 23:13:05,980:INFO:Creating metrics dataframe
2024-03-24 23:13:05,988:INFO:Initializing K Neighbors Classifier
2024-03-24 23:13:05,988:INFO:Total runtime is 0.041399641831715905 minutes
2024-03-24 23:13:05,990:INFO:SubProcess create_model() called ==================================
2024-03-24 23:13:05,991:INFO:Initializing create_model()
2024-03-24 23:13:05,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbe243af220>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbcbc0503a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:13:05,991:INFO:Checking exceptions
2024-03-24 23:13:05,991:INFO:Importing libraries
2024-03-24 23:13:05,991:INFO:Copying training dataset
2024-03-24 23:13:05,993:INFO:Defining folds
2024-03-24 23:13:05,993:INFO:Declaring metric variables
2024-03-24 23:13:05,996:INFO:Importing untrained model
2024-03-24 23:13:05,998:INFO:K Neighbors Classifier Imported successfully
2024-03-24 23:13:06,003:INFO:Starting cross validation
2024-03-24 23:13:06,004:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:13:07,191:INFO:Calculating mean and std
2024-03-24 23:13:07,193:INFO:Creating metrics dataframe
2024-03-24 23:13:07,196:INFO:Uploading results into container
2024-03-24 23:13:07,197:INFO:Uploading model into container now
2024-03-24 23:13:07,197:INFO:_master_model_container: 2
2024-03-24 23:13:07,197:INFO:_display_container: 2
2024-03-24 23:13:07,198:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-03-24 23:13:07,198:INFO:create_model() successfully completed......................................
2024-03-24 23:13:07,272:INFO:SubProcess create_model() end ==================================
2024-03-24 23:13:07,272:INFO:Creating metrics dataframe
2024-03-24 23:13:07,281:INFO:Initializing Naive Bayes
2024-03-24 23:13:07,281:INFO:Total runtime is 0.06295036872227987 minutes
2024-03-24 23:13:07,283:INFO:SubProcess create_model() called ==================================
2024-03-24 23:13:07,284:INFO:Initializing create_model()
2024-03-24 23:13:07,284:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbe243af220>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbcbc0503a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:13:07,284:INFO:Checking exceptions
2024-03-24 23:13:07,284:INFO:Importing libraries
2024-03-24 23:13:07,284:INFO:Copying training dataset
2024-03-24 23:13:07,287:INFO:Defining folds
2024-03-24 23:13:07,287:INFO:Declaring metric variables
2024-03-24 23:13:07,289:INFO:Importing untrained model
2024-03-24 23:13:07,292:INFO:Naive Bayes Imported successfully
2024-03-24 23:13:07,298:INFO:Starting cross validation
2024-03-24 23:13:07,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:13:08,396:INFO:Calculating mean and std
2024-03-24 23:13:08,397:INFO:Creating metrics dataframe
2024-03-24 23:13:08,402:INFO:Uploading results into container
2024-03-24 23:13:08,403:INFO:Uploading model into container now
2024-03-24 23:13:08,404:INFO:_master_model_container: 3
2024-03-24 23:13:08,404:INFO:_display_container: 2
2024-03-24 23:13:08,404:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-03-24 23:13:08,404:INFO:create_model() successfully completed......................................
2024-03-24 23:13:08,497:INFO:SubProcess create_model() end ==================================
2024-03-24 23:13:08,497:INFO:Creating metrics dataframe
2024-03-24 23:13:08,506:INFO:Initializing Decision Tree Classifier
2024-03-24 23:13:08,506:INFO:Total runtime is 0.0833779255549113 minutes
2024-03-24 23:13:08,509:INFO:SubProcess create_model() called ==================================
2024-03-24 23:13:08,509:INFO:Initializing create_model()
2024-03-24 23:13:08,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbe243af220>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbcbc0503a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:13:08,510:INFO:Checking exceptions
2024-03-24 23:13:08,510:INFO:Importing libraries
2024-03-24 23:13:08,510:INFO:Copying training dataset
2024-03-24 23:13:08,513:INFO:Defining folds
2024-03-24 23:13:08,513:INFO:Declaring metric variables
2024-03-24 23:13:08,516:INFO:Importing untrained model
2024-03-24 23:13:08,518:INFO:Decision Tree Classifier Imported successfully
2024-03-24 23:13:08,523:INFO:Starting cross validation
2024-03-24 23:13:08,524:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:13:09,622:INFO:Calculating mean and std
2024-03-24 23:13:09,623:INFO:Creating metrics dataframe
2024-03-24 23:13:09,627:INFO:Uploading results into container
2024-03-24 23:13:09,627:INFO:Uploading model into container now
2024-03-24 23:13:09,627:INFO:_master_model_container: 4
2024-03-24 23:13:09,627:INFO:_display_container: 2
2024-03-24 23:13:09,628:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-03-24 23:13:09,628:INFO:create_model() successfully completed......................................
2024-03-24 23:13:09,702:INFO:SubProcess create_model() end ==================================
2024-03-24 23:13:09,702:INFO:Creating metrics dataframe
2024-03-24 23:13:09,711:INFO:Initializing SVM - Linear Kernel
2024-03-24 23:13:09,711:INFO:Total runtime is 0.1034541408220927 minutes
2024-03-24 23:13:09,714:INFO:SubProcess create_model() called ==================================
2024-03-24 23:13:09,714:INFO:Initializing create_model()
2024-03-24 23:13:09,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbe243af220>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbcbc0503a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:13:09,714:INFO:Checking exceptions
2024-03-24 23:13:09,714:INFO:Importing libraries
2024-03-24 23:13:09,714:INFO:Copying training dataset
2024-03-24 23:13:09,717:INFO:Defining folds
2024-03-24 23:13:09,717:INFO:Declaring metric variables
2024-03-24 23:13:09,719:INFO:Importing untrained model
2024-03-24 23:13:09,722:INFO:SVM - Linear Kernel Imported successfully
2024-03-24 23:13:09,727:INFO:Starting cross validation
2024-03-24 23:13:09,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:13:10,711:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:13:10,713:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:13:10,716:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:13:10,718:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:13:10,718:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:13:10,720:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:13:10,724:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:13:10,724:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:13:10,726:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:13:10,727:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:13:10,744:INFO:Calculating mean and std
2024-03-24 23:13:10,746:INFO:Creating metrics dataframe
2024-03-24 23:13:10,750:INFO:Uploading results into container
2024-03-24 23:13:10,750:INFO:Uploading model into container now
2024-03-24 23:13:10,751:INFO:_master_model_container: 5
2024-03-24 23:13:10,751:INFO:_display_container: 2
2024-03-24 23:13:10,752:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-03-24 23:13:10,752:INFO:create_model() successfully completed......................................
2024-03-24 23:13:10,832:INFO:SubProcess create_model() end ==================================
2024-03-24 23:13:10,832:INFO:Creating metrics dataframe
2024-03-24 23:13:10,842:INFO:Initializing Ridge Classifier
2024-03-24 23:13:10,842:INFO:Total runtime is 0.12230784495671591 minutes
2024-03-24 23:13:10,845:INFO:SubProcess create_model() called ==================================
2024-03-24 23:13:10,846:INFO:Initializing create_model()
2024-03-24 23:13:10,846:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbe243af220>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbcbc0503a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:13:10,846:INFO:Checking exceptions
2024-03-24 23:13:10,846:INFO:Importing libraries
2024-03-24 23:13:10,846:INFO:Copying training dataset
2024-03-24 23:13:10,849:INFO:Defining folds
2024-03-24 23:13:10,849:INFO:Declaring metric variables
2024-03-24 23:13:10,852:INFO:Importing untrained model
2024-03-24 23:13:10,855:INFO:Ridge Classifier Imported successfully
2024-03-24 23:13:10,860:INFO:Starting cross validation
2024-03-24 23:13:10,861:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:13:11,842:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:13:11,843:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:13:11,847:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:13:11,849:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:13:11,849:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:13:11,849:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:13:11,851:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:13:11,854:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:13:11,857:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:13:11,858:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:13:11,867:INFO:Calculating mean and std
2024-03-24 23:13:11,869:INFO:Creating metrics dataframe
2024-03-24 23:13:11,872:INFO:Uploading results into container
2024-03-24 23:13:11,872:INFO:Uploading model into container now
2024-03-24 23:13:11,873:INFO:_master_model_container: 6
2024-03-24 23:13:11,873:INFO:_display_container: 2
2024-03-24 23:13:11,873:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-03-24 23:13:11,873:INFO:create_model() successfully completed......................................
2024-03-24 23:13:11,952:INFO:SubProcess create_model() end ==================================
2024-03-24 23:13:11,952:INFO:Creating metrics dataframe
2024-03-24 23:13:11,962:INFO:Initializing Random Forest Classifier
2024-03-24 23:13:11,962:INFO:Total runtime is 0.14097459316253663 minutes
2024-03-24 23:13:11,965:INFO:SubProcess create_model() called ==================================
2024-03-24 23:13:11,966:INFO:Initializing create_model()
2024-03-24 23:13:11,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbe243af220>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbcbc0503a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:13:11,966:INFO:Checking exceptions
2024-03-24 23:13:11,966:INFO:Importing libraries
2024-03-24 23:13:11,966:INFO:Copying training dataset
2024-03-24 23:13:11,969:INFO:Defining folds
2024-03-24 23:13:11,969:INFO:Declaring metric variables
2024-03-24 23:13:11,972:INFO:Importing untrained model
2024-03-24 23:13:11,975:INFO:Random Forest Classifier Imported successfully
2024-03-24 23:13:11,980:INFO:Starting cross validation
2024-03-24 23:13:11,981:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:13:13,259:INFO:Calculating mean and std
2024-03-24 23:13:13,261:INFO:Creating metrics dataframe
2024-03-24 23:13:13,264:INFO:Uploading results into container
2024-03-24 23:13:13,265:INFO:Uploading model into container now
2024-03-24 23:13:13,265:INFO:_master_model_container: 7
2024-03-24 23:13:13,265:INFO:_display_container: 2
2024-03-24 23:13:13,265:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-03-24 23:13:13,266:INFO:create_model() successfully completed......................................
2024-03-24 23:13:13,341:INFO:SubProcess create_model() end ==================================
2024-03-24 23:13:13,341:INFO:Creating metrics dataframe
2024-03-24 23:13:13,351:INFO:Initializing Quadratic Discriminant Analysis
2024-03-24 23:13:13,352:INFO:Total runtime is 0.16412927707036337 minutes
2024-03-24 23:13:13,354:INFO:SubProcess create_model() called ==================================
2024-03-24 23:13:13,355:INFO:Initializing create_model()
2024-03-24 23:13:13,355:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbe243af220>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbcbc0503a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:13:13,355:INFO:Checking exceptions
2024-03-24 23:13:13,355:INFO:Importing libraries
2024-03-24 23:13:13,355:INFO:Copying training dataset
2024-03-24 23:13:13,357:INFO:Defining folds
2024-03-24 23:13:13,357:INFO:Declaring metric variables
2024-03-24 23:13:13,360:INFO:Importing untrained model
2024-03-24 23:13:13,363:INFO:Quadratic Discriminant Analysis Imported successfully
2024-03-24 23:13:13,369:INFO:Starting cross validation
2024-03-24 23:13:13,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:13:14,386:INFO:Calculating mean and std
2024-03-24 23:13:14,386:INFO:Creating metrics dataframe
2024-03-24 23:13:14,390:INFO:Uploading results into container
2024-03-24 23:13:14,391:INFO:Uploading model into container now
2024-03-24 23:13:14,392:INFO:_master_model_container: 8
2024-03-24 23:13:14,392:INFO:_display_container: 2
2024-03-24 23:13:14,392:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-03-24 23:13:14,392:INFO:create_model() successfully completed......................................
2024-03-24 23:13:14,492:INFO:SubProcess create_model() end ==================================
2024-03-24 23:13:14,492:INFO:Creating metrics dataframe
2024-03-24 23:13:14,504:INFO:Initializing Ada Boost Classifier
2024-03-24 23:13:14,504:INFO:Total runtime is 0.1833311915397644 minutes
2024-03-24 23:13:14,507:INFO:SubProcess create_model() called ==================================
2024-03-24 23:13:14,507:INFO:Initializing create_model()
2024-03-24 23:13:14,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbe243af220>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbcbc0503a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:13:14,507:INFO:Checking exceptions
2024-03-24 23:13:14,507:INFO:Importing libraries
2024-03-24 23:13:14,507:INFO:Copying training dataset
2024-03-24 23:13:14,510:INFO:Defining folds
2024-03-24 23:13:14,510:INFO:Declaring metric variables
2024-03-24 23:13:14,512:INFO:Importing untrained model
2024-03-24 23:13:14,515:INFO:Ada Boost Classifier Imported successfully
2024-03-24 23:13:14,521:INFO:Starting cross validation
2024-03-24 23:13:14,522:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:13:15,598:INFO:Calculating mean and std
2024-03-24 23:13:15,599:INFO:Creating metrics dataframe
2024-03-24 23:13:15,602:INFO:Uploading results into container
2024-03-24 23:13:15,603:INFO:Uploading model into container now
2024-03-24 23:13:15,603:INFO:_master_model_container: 9
2024-03-24 23:13:15,603:INFO:_display_container: 2
2024-03-24 23:13:15,603:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-03-24 23:13:15,603:INFO:create_model() successfully completed......................................
2024-03-24 23:13:15,677:INFO:SubProcess create_model() end ==================================
2024-03-24 23:13:15,677:INFO:Creating metrics dataframe
2024-03-24 23:13:15,688:INFO:Initializing Gradient Boosting Classifier
2024-03-24 23:13:15,688:INFO:Total runtime is 0.20307456652323405 minutes
2024-03-24 23:13:15,691:INFO:SubProcess create_model() called ==================================
2024-03-24 23:13:15,691:INFO:Initializing create_model()
2024-03-24 23:13:15,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbe243af220>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbcbc0503a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:13:15,691:INFO:Checking exceptions
2024-03-24 23:13:15,691:INFO:Importing libraries
2024-03-24 23:13:15,691:INFO:Copying training dataset
2024-03-24 23:13:15,694:INFO:Defining folds
2024-03-24 23:13:15,694:INFO:Declaring metric variables
2024-03-24 23:13:15,696:INFO:Importing untrained model
2024-03-24 23:13:15,699:INFO:Gradient Boosting Classifier Imported successfully
2024-03-24 23:13:15,704:INFO:Starting cross validation
2024-03-24 23:13:15,705:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:13:16,782:INFO:Calculating mean and std
2024-03-24 23:13:16,783:INFO:Creating metrics dataframe
2024-03-24 23:13:16,786:INFO:Uploading results into container
2024-03-24 23:13:16,787:INFO:Uploading model into container now
2024-03-24 23:13:16,787:INFO:_master_model_container: 10
2024-03-24 23:13:16,787:INFO:_display_container: 2
2024-03-24 23:13:16,788:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-24 23:13:16,788:INFO:create_model() successfully completed......................................
2024-03-24 23:13:16,855:INFO:SubProcess create_model() end ==================================
2024-03-24 23:13:16,855:INFO:Creating metrics dataframe
2024-03-24 23:13:16,866:INFO:Initializing Linear Discriminant Analysis
2024-03-24 23:13:16,866:INFO:Total runtime is 0.22270225286483764 minutes
2024-03-24 23:13:16,869:INFO:SubProcess create_model() called ==================================
2024-03-24 23:13:16,869:INFO:Initializing create_model()
2024-03-24 23:13:16,869:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbe243af220>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbcbc0503a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:13:16,869:INFO:Checking exceptions
2024-03-24 23:13:16,869:INFO:Importing libraries
2024-03-24 23:13:16,869:INFO:Copying training dataset
2024-03-24 23:13:16,871:INFO:Defining folds
2024-03-24 23:13:16,872:INFO:Declaring metric variables
2024-03-24 23:13:16,874:INFO:Importing untrained model
2024-03-24 23:13:16,877:INFO:Linear Discriminant Analysis Imported successfully
2024-03-24 23:13:16,882:INFO:Starting cross validation
2024-03-24 23:13:16,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:13:17,900:INFO:Calculating mean and std
2024-03-24 23:13:17,901:INFO:Creating metrics dataframe
2024-03-24 23:13:17,904:INFO:Uploading results into container
2024-03-24 23:13:17,904:INFO:Uploading model into container now
2024-03-24 23:13:17,905:INFO:_master_model_container: 11
2024-03-24 23:13:17,905:INFO:_display_container: 2
2024-03-24 23:13:17,905:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-03-24 23:13:17,905:INFO:create_model() successfully completed......................................
2024-03-24 23:13:17,973:INFO:SubProcess create_model() end ==================================
2024-03-24 23:13:17,973:INFO:Creating metrics dataframe
2024-03-24 23:13:17,984:INFO:Initializing Extra Trees Classifier
2024-03-24 23:13:17,984:INFO:Total runtime is 0.24133658011754353 minutes
2024-03-24 23:13:17,987:INFO:SubProcess create_model() called ==================================
2024-03-24 23:13:17,987:INFO:Initializing create_model()
2024-03-24 23:13:17,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbe243af220>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbcbc0503a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:13:17,987:INFO:Checking exceptions
2024-03-24 23:13:17,987:INFO:Importing libraries
2024-03-24 23:13:17,987:INFO:Copying training dataset
2024-03-24 23:13:17,990:INFO:Defining folds
2024-03-24 23:13:17,990:INFO:Declaring metric variables
2024-03-24 23:13:17,992:INFO:Importing untrained model
2024-03-24 23:13:17,995:INFO:Extra Trees Classifier Imported successfully
2024-03-24 23:13:18,000:INFO:Starting cross validation
2024-03-24 23:13:18,001:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:13:19,239:INFO:Calculating mean and std
2024-03-24 23:13:19,241:INFO:Creating metrics dataframe
2024-03-24 23:13:19,244:INFO:Uploading results into container
2024-03-24 23:13:19,245:INFO:Uploading model into container now
2024-03-24 23:13:19,245:INFO:_master_model_container: 12
2024-03-24 23:13:19,245:INFO:_display_container: 2
2024-03-24 23:13:19,245:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-03-24 23:13:19,246:INFO:create_model() successfully completed......................................
2024-03-24 23:13:19,314:INFO:SubProcess create_model() end ==================================
2024-03-24 23:13:19,315:INFO:Creating metrics dataframe
2024-03-24 23:13:19,326:INFO:Initializing Light Gradient Boosting Machine
2024-03-24 23:13:19,326:INFO:Total runtime is 0.26371121803919473 minutes
2024-03-24 23:13:19,329:INFO:SubProcess create_model() called ==================================
2024-03-24 23:13:19,329:INFO:Initializing create_model()
2024-03-24 23:13:19,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbe243af220>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbcbc0503a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:13:19,330:INFO:Checking exceptions
2024-03-24 23:13:19,330:INFO:Importing libraries
2024-03-24 23:13:19,330:INFO:Copying training dataset
2024-03-24 23:13:19,332:INFO:Defining folds
2024-03-24 23:13:19,332:INFO:Declaring metric variables
2024-03-24 23:13:19,335:INFO:Importing untrained model
2024-03-24 23:13:19,338:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-24 23:13:19,343:INFO:Starting cross validation
2024-03-24 23:13:19,344:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-24 23:16:01,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:01,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:01,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:01,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,110:INFO:PyCaret ClassificationExperiment
2024-03-24 23:16:02,110:INFO:Logging name: clf-default-name
2024-03-24 23:16:02,110:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-24 23:16:02,110:INFO:version 3.2.0
2024-03-24 23:16:02,110:INFO:Initializing setup()
2024-03-24 23:16:02,110:INFO:self.USI: 4495
2024-03-24 23:16:02,110:INFO:self._variable_keys: {'is_multiclass', 'logging_param', 'fix_imbalance', 'fold_shuffle_param', 'html_param', '_ml_usecase', 'y_train', 'USI', 'y_test', 'seed', '_available_plots', 'X', 'target_param', 'pipeline', 'memory', 'idx', 'X_test', 'data', 'fold_groups_param', 'log_plots_param', 'X_train', 'exp_name_log', 'n_jobs_param', 'gpu_n_jobs_param', 'exp_id', 'y', 'fold_generator', 'gpu_param'}
2024-03-24 23:16:02,110:INFO:Checking environment
2024-03-24 23:16:02,110:INFO:python_version: 3.8.19
2024-03-24 23:16:02,110:INFO:python_build: ('default', 'Mar 20 2024 19:58:24')
2024-03-24 23:16:02,110:INFO:machine: x86_64
2024-03-24 23:16:02,133:INFO:platform: Linux-5.15.0-1044-nvidia-x86_64-with-glibc2.17
2024-03-24 23:16:02,133:INFO:Memory: svmem(total=540860575744, available=470188617728, percent=13.1, used=67109371904, free=111614455808, active=130979201024, inactive=269538336768, buffers=9814007808, cached=352322740224, shared=41619456, slab=25452339200)
2024-03-24 23:16:02,137:INFO:Physical Core: 64
2024-03-24 23:16:02,137:INFO:Logical Core: 128
2024-03-24 23:16:02,137:INFO:Checking libraries
2024-03-24 23:16:02,137:INFO:System:
2024-03-24 23:16:02,137:INFO:    python: 3.8.19 (default, Mar 20 2024, 19:58:24)  [GCC 11.2.0]
2024-03-24 23:16:02,137:INFO:executable: /root/anaconda3/envs/pc/bin/python
2024-03-24 23:16:02,137:INFO:   machine: Linux-5.15.0-1044-nvidia-x86_64-with-glibc2.17
2024-03-24 23:16:02,137:INFO:PyCaret required dependencies:
2024-03-24 23:16:02,155:INFO:                 pip: 23.3.1
2024-03-24 23:16:02,155:INFO:          setuptools: 68.2.2
2024-03-24 23:16:02,155:INFO:             pycaret: 3.2.0
2024-03-24 23:16:02,155:INFO:             IPython: 8.12.0
2024-03-24 23:16:02,155:INFO:          ipywidgets: 8.1.2
2024-03-24 23:16:02,155:INFO:                tqdm: 4.66.2
2024-03-24 23:16:02,155:INFO:               numpy: 1.24.4
2024-03-24 23:16:02,155:INFO:              pandas: 1.5.3
2024-03-24 23:16:02,155:INFO:              jinja2: 3.1.3
2024-03-24 23:16:02,155:INFO:               scipy: 1.10.1
2024-03-24 23:16:02,155:INFO:              joblib: 1.3.2
2024-03-24 23:16:02,155:INFO:             sklearn: 1.2.2
2024-03-24 23:16:02,155:INFO:                pyod: 1.1.3
2024-03-24 23:16:02,155:INFO:            imblearn: 0.12.0
2024-03-24 23:16:02,155:INFO:   category_encoders: 2.6.3
2024-03-24 23:16:02,155:INFO:            lightgbm: 4.3.0
2024-03-24 23:16:02,155:INFO:               numba: 0.58.1
2024-03-24 23:16:02,155:INFO:            requests: 2.31.0
2024-03-24 23:16:02,155:INFO:          matplotlib: 3.6.0
2024-03-24 23:16:02,155:INFO:          scikitplot: 0.3.7
2024-03-24 23:16:02,155:INFO:         yellowbrick: 1.5
2024-03-24 23:16:02,155:INFO:              plotly: 5.20.0
2024-03-24 23:16:02,155:INFO:    plotly-resampler: Not installed
2024-03-24 23:16:02,155:INFO:             kaleido: 0.2.1
2024-03-24 23:16:02,155:INFO:           schemdraw: 0.15
2024-03-24 23:16:02,155:INFO:         statsmodels: 0.14.1
2024-03-24 23:16:02,155:INFO:              sktime: 0.21.1
2024-03-24 23:16:02,155:INFO:               tbats: 1.1.3
2024-03-24 23:16:02,155:INFO:            pmdarima: 2.0.4
2024-03-24 23:16:02,155:INFO:              psutil: 5.9.8
2024-03-24 23:16:02,155:INFO:          markupsafe: 2.1.3
2024-03-24 23:16:02,155:INFO:             pickle5: Not installed
2024-03-24 23:16:02,155:INFO:         cloudpickle: 3.0.0
2024-03-24 23:16:02,156:INFO:         deprecation: 2.1.0
2024-03-24 23:16:02,156:INFO:              xxhash: 3.4.1
2024-03-24 23:16:02,156:INFO:           wurlitzer: 3.0.3
2024-03-24 23:16:02,156:INFO:PyCaret optional dependencies:
2024-03-24 23:16:02,170:INFO:                shap: Not installed
2024-03-24 23:16:02,170:INFO:           interpret: Not installed
2024-03-24 23:16:02,170:INFO:                umap: Not installed
2024-03-24 23:16:02,170:INFO:     ydata_profiling: Not installed
2024-03-24 23:16:02,170:INFO:  explainerdashboard: Not installed
2024-03-24 23:16:02,170:INFO:             autoviz: Not installed
2024-03-24 23:16:02,170:INFO:           fairlearn: Not installed
2024-03-24 23:16:02,170:INFO:          deepchecks: Not installed
2024-03-24 23:16:02,170:INFO:             xgboost: Not installed
2024-03-24 23:16:02,170:INFO:            catboost: Not installed
2024-03-24 23:16:02,170:INFO:              kmodes: Not installed
2024-03-24 23:16:02,170:INFO:             mlxtend: Not installed
2024-03-24 23:16:02,170:INFO:       statsforecast: Not installed
2024-03-24 23:16:02,170:INFO:        tune_sklearn: Not installed
2024-03-24 23:16:02,170:INFO:                 ray: Not installed
2024-03-24 23:16:02,170:INFO:            hyperopt: Not installed
2024-03-24 23:16:02,170:INFO:              optuna: Not installed
2024-03-24 23:16:02,170:INFO:               skopt: Not installed
2024-03-24 23:16:02,170:INFO:              mlflow: Not installed
2024-03-24 23:16:02,170:INFO:              gradio: Not installed
2024-03-24 23:16:02,170:INFO:             fastapi: Not installed
2024-03-24 23:16:02,170:INFO:             uvicorn: Not installed
2024-03-24 23:16:02,170:INFO:              m2cgen: Not installed
2024-03-24 23:16:02,170:INFO:           evidently: Not installed
2024-03-24 23:16:02,170:INFO:               fugue: Not installed
2024-03-24 23:16:02,170:INFO:           streamlit: Not installed
2024-03-24 23:16:02,170:INFO:             prophet: Not installed
2024-03-24 23:16:02,170:INFO:None
2024-03-24 23:16:02,170:INFO:Set up GPU usage.
2024-03-24 23:16:02,170:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,170:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-03-24 23:16:02,170:INFO:Set up data.
2024-03-24 23:16:02,174:INFO:Set up folding strategy.
2024-03-24 23:16:02,174:INFO:Set up train/test split.
2024-03-24 23:16:02,177:INFO:Set up index.
2024-03-24 23:16:02,177:INFO:Assigning column types.
2024-03-24 23:16:02,180:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-24 23:16:02,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-24 23:16:02,226:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,227:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-24 23:16:02,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,251:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,256:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:16:02,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:16:02,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,383:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-24 23:16:02,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,384:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-24 23:16:02,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,407:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,412:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,413:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:16:02,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:16:02,417:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-24 23:16:02,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,467:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-24 23:16:02,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,490:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,495:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,496:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:16:02,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:16:02,501:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,550:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-24 23:16:02,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,578:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:16:02,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:16:02,585:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-24 23:16:02,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,654:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,659:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:16:02,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:16:02,664:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,712:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,735:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,740:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:16:02,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:16:02,747:INFO:Preparing preprocessing pipeline...
2024-03-24 23:16:02,748:INFO:Set up simple imputation.
2024-03-24 23:16:02,762:INFO:Finished creating preprocessing pipeline.
2024-03-24 23:16:02,766:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'SibSp', 'Age', 'Sex'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2024-03-24 23:16:02,766:INFO:Creating final display dataframe.
2024-03-24 23:16:02,814:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 5)
4        Transformed data shape          (891, 5)
5   Transformed train set shape          (623, 5)
6    Transformed test set shape          (268, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              4495
2024-03-24 23:16:02,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,866:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,866:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,866:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,890:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:16:02,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:16:02,900:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,950:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:16:02,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:16:02,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:16:02,984:INFO:setup() successfully completed in 0.87s...............
2024-03-24 23:16:02,984:INFO:Initializing compare_models()
2024-03-24 23:16:02,984:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-03-24 23:16:02,984:INFO:Checking exceptions
2024-03-24 23:16:02,986:INFO:Preparing display monitor
2024-03-24 23:16:03,011:INFO:Initializing Logistic Regression
2024-03-24 23:16:03,011:INFO:Total runtime is 2.777576446533203e-06 minutes
2024-03-24 23:16:03,014:INFO:SubProcess create_model() called ==================================
2024-03-24 23:16:03,015:INFO:Initializing create_model()
2024-03-24 23:16:03,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6a3508d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:16:03,015:INFO:Checking exceptions
2024-03-24 23:16:03,015:INFO:Importing libraries
2024-03-24 23:16:03,015:INFO:Copying training dataset
2024-03-24 23:16:03,018:INFO:Defining folds
2024-03-24 23:16:03,018:INFO:Declaring metric variables
2024-03-24 23:16:03,020:INFO:Importing untrained model
2024-03-24 23:16:03,023:INFO:Logistic Regression Imported successfully
2024-03-24 23:16:03,028:INFO:Starting cross validation
2024-03-24 23:16:03,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:16:03,248:INFO:Calculating mean and std
2024-03-24 23:16:03,248:INFO:Creating metrics dataframe
2024-03-24 23:16:03,251:INFO:Uploading results into container
2024-03-24 23:16:03,251:INFO:Uploading model into container now
2024-03-24 23:16:03,251:INFO:_master_model_container: 1
2024-03-24 23:16:03,251:INFO:_display_container: 2
2024-03-24 23:16:03,252:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-03-24 23:16:03,252:INFO:create_model() successfully completed......................................
2024-03-24 23:16:03,329:INFO:SubProcess create_model() end ==================================
2024-03-24 23:16:03,329:INFO:Creating metrics dataframe
2024-03-24 23:16:03,337:INFO:Initializing K Neighbors Classifier
2024-03-24 23:16:03,338:INFO:Total runtime is 0.005440084139506023 minutes
2024-03-24 23:16:03,341:INFO:SubProcess create_model() called ==================================
2024-03-24 23:16:03,341:INFO:Initializing create_model()
2024-03-24 23:16:03,341:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6a3508d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:16:03,341:INFO:Checking exceptions
2024-03-24 23:16:03,341:INFO:Importing libraries
2024-03-24 23:16:03,341:INFO:Copying training dataset
2024-03-24 23:16:03,344:INFO:Defining folds
2024-03-24 23:16:03,344:INFO:Declaring metric variables
2024-03-24 23:16:03,347:INFO:Importing untrained model
2024-03-24 23:16:03,350:INFO:K Neighbors Classifier Imported successfully
2024-03-24 23:16:03,355:INFO:Starting cross validation
2024-03-24 23:16:03,356:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:16:04,122:INFO:Calculating mean and std
2024-03-24 23:16:04,123:INFO:Creating metrics dataframe
2024-03-24 23:16:04,126:INFO:Uploading results into container
2024-03-24 23:16:04,127:INFO:Uploading model into container now
2024-03-24 23:16:04,127:INFO:_master_model_container: 2
2024-03-24 23:16:04,127:INFO:_display_container: 2
2024-03-24 23:16:04,128:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-03-24 23:16:04,128:INFO:create_model() successfully completed......................................
2024-03-24 23:16:04,197:INFO:SubProcess create_model() end ==================================
2024-03-24 23:16:04,197:INFO:Creating metrics dataframe
2024-03-24 23:16:04,206:INFO:Initializing Naive Bayes
2024-03-24 23:16:04,206:INFO:Total runtime is 0.01992031733194987 minutes
2024-03-24 23:16:04,209:INFO:SubProcess create_model() called ==================================
2024-03-24 23:16:04,210:INFO:Initializing create_model()
2024-03-24 23:16:04,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6a3508d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:16:04,210:INFO:Checking exceptions
2024-03-24 23:16:04,210:INFO:Importing libraries
2024-03-24 23:16:04,210:INFO:Copying training dataset
2024-03-24 23:16:04,213:INFO:Defining folds
2024-03-24 23:16:04,213:INFO:Declaring metric variables
2024-03-24 23:16:04,216:INFO:Importing untrained model
2024-03-24 23:16:04,219:INFO:Naive Bayes Imported successfully
2024-03-24 23:16:04,225:INFO:Starting cross validation
2024-03-24 23:16:04,226:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:16:04,398:INFO:Calculating mean and std
2024-03-24 23:16:04,399:INFO:Creating metrics dataframe
2024-03-24 23:16:04,401:INFO:Uploading results into container
2024-03-24 23:16:04,402:INFO:Uploading model into container now
2024-03-24 23:16:04,402:INFO:_master_model_container: 3
2024-03-24 23:16:04,402:INFO:_display_container: 2
2024-03-24 23:16:04,403:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-03-24 23:16:04,403:INFO:create_model() successfully completed......................................
2024-03-24 23:16:04,467:INFO:SubProcess create_model() end ==================================
2024-03-24 23:16:04,467:INFO:Creating metrics dataframe
2024-03-24 23:16:04,476:INFO:Initializing Decision Tree Classifier
2024-03-24 23:16:04,476:INFO:Total runtime is 0.024412326018015545 minutes
2024-03-24 23:16:04,478:INFO:SubProcess create_model() called ==================================
2024-03-24 23:16:04,479:INFO:Initializing create_model()
2024-03-24 23:16:04,479:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6a3508d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:16:04,479:INFO:Checking exceptions
2024-03-24 23:16:04,479:INFO:Importing libraries
2024-03-24 23:16:04,479:INFO:Copying training dataset
2024-03-24 23:16:04,482:INFO:Defining folds
2024-03-24 23:16:04,482:INFO:Declaring metric variables
2024-03-24 23:16:04,485:INFO:Importing untrained model
2024-03-24 23:16:04,487:INFO:Decision Tree Classifier Imported successfully
2024-03-24 23:16:04,493:INFO:Starting cross validation
2024-03-24 23:16:04,494:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:16:04,665:INFO:Calculating mean and std
2024-03-24 23:16:04,666:INFO:Creating metrics dataframe
2024-03-24 23:16:04,669:INFO:Uploading results into container
2024-03-24 23:16:04,669:INFO:Uploading model into container now
2024-03-24 23:16:04,670:INFO:_master_model_container: 4
2024-03-24 23:16:04,670:INFO:_display_container: 2
2024-03-24 23:16:04,670:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-03-24 23:16:04,670:INFO:create_model() successfully completed......................................
2024-03-24 23:16:04,734:INFO:SubProcess create_model() end ==================================
2024-03-24 23:16:04,734:INFO:Creating metrics dataframe
2024-03-24 23:16:04,743:INFO:Initializing SVM - Linear Kernel
2024-03-24 23:16:04,743:INFO:Total runtime is 0.02887232303619385 minutes
2024-03-24 23:16:04,746:INFO:SubProcess create_model() called ==================================
2024-03-24 23:16:04,747:INFO:Initializing create_model()
2024-03-24 23:16:04,747:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6a3508d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:16:04,747:INFO:Checking exceptions
2024-03-24 23:16:04,747:INFO:Importing libraries
2024-03-24 23:16:04,747:INFO:Copying training dataset
2024-03-24 23:16:04,750:INFO:Defining folds
2024-03-24 23:16:04,750:INFO:Declaring metric variables
2024-03-24 23:16:04,753:INFO:Importing untrained model
2024-03-24 23:16:04,756:INFO:SVM - Linear Kernel Imported successfully
2024-03-24 23:16:04,761:INFO:Starting cross validation
2024-03-24 23:16:04,761:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:16:04,774:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:16:04,791:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:16:04,808:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:16:04,823:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:16:04,839:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:16:04,855:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:16:04,871:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:16:04,887:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:16:04,903:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:16:04,920:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:16:04,926:INFO:Calculating mean and std
2024-03-24 23:16:04,927:INFO:Creating metrics dataframe
2024-03-24 23:16:04,930:INFO:Uploading results into container
2024-03-24 23:16:04,930:INFO:Uploading model into container now
2024-03-24 23:16:04,930:INFO:_master_model_container: 5
2024-03-24 23:16:04,930:INFO:_display_container: 2
2024-03-24 23:16:04,931:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-03-24 23:16:04,931:INFO:create_model() successfully completed......................................
2024-03-24 23:16:04,996:INFO:SubProcess create_model() end ==================================
2024-03-24 23:16:04,996:INFO:Creating metrics dataframe
2024-03-24 23:16:05,005:INFO:Initializing Ridge Classifier
2024-03-24 23:16:05,005:INFO:Total runtime is 0.03323874076207479 minutes
2024-03-24 23:16:05,008:INFO:SubProcess create_model() called ==================================
2024-03-24 23:16:05,009:INFO:Initializing create_model()
2024-03-24 23:16:05,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6a3508d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:16:05,009:INFO:Checking exceptions
2024-03-24 23:16:05,009:INFO:Importing libraries
2024-03-24 23:16:05,009:INFO:Copying training dataset
2024-03-24 23:16:05,011:INFO:Defining folds
2024-03-24 23:16:05,011:INFO:Declaring metric variables
2024-03-24 23:16:05,014:INFO:Importing untrained model
2024-03-24 23:16:05,016:INFO:Ridge Classifier Imported successfully
2024-03-24 23:16:05,021:INFO:Starting cross validation
2024-03-24 23:16:05,022:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:16:05,034:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:16:05,050:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:16:05,066:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:16:05,082:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:16:05,097:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:16:05,113:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:16:05,128:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:16:05,144:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:16:05,159:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:16:05,175:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:16:05,181:INFO:Calculating mean and std
2024-03-24 23:16:05,182:INFO:Creating metrics dataframe
2024-03-24 23:16:05,185:INFO:Uploading results into container
2024-03-24 23:16:05,185:INFO:Uploading model into container now
2024-03-24 23:16:05,186:INFO:_master_model_container: 6
2024-03-24 23:16:05,186:INFO:_display_container: 2
2024-03-24 23:16:05,186:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-03-24 23:16:05,186:INFO:create_model() successfully completed......................................
2024-03-24 23:16:05,250:INFO:SubProcess create_model() end ==================================
2024-03-24 23:16:05,250:INFO:Creating metrics dataframe
2024-03-24 23:16:05,260:INFO:Initializing Random Forest Classifier
2024-03-24 23:16:05,260:INFO:Total runtime is 0.03748057683308919 minutes
2024-03-24 23:16:05,263:INFO:SubProcess create_model() called ==================================
2024-03-24 23:16:05,263:INFO:Initializing create_model()
2024-03-24 23:16:05,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6a3508d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:16:05,263:INFO:Checking exceptions
2024-03-24 23:16:05,263:INFO:Importing libraries
2024-03-24 23:16:05,263:INFO:Copying training dataset
2024-03-24 23:16:05,266:INFO:Defining folds
2024-03-24 23:16:05,266:INFO:Declaring metric variables
2024-03-24 23:16:05,268:INFO:Importing untrained model
2024-03-24 23:16:05,271:INFO:Random Forest Classifier Imported successfully
2024-03-24 23:16:05,276:INFO:Starting cross validation
2024-03-24 23:16:05,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:16:07,650:INFO:Calculating mean and std
2024-03-24 23:16:07,651:INFO:Creating metrics dataframe
2024-03-24 23:16:07,655:INFO:Uploading results into container
2024-03-24 23:16:07,655:INFO:Uploading model into container now
2024-03-24 23:16:07,655:INFO:_master_model_container: 7
2024-03-24 23:16:07,655:INFO:_display_container: 2
2024-03-24 23:16:07,656:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-03-24 23:16:07,656:INFO:create_model() successfully completed......................................
2024-03-24 23:16:07,721:INFO:SubProcess create_model() end ==================================
2024-03-24 23:16:07,721:INFO:Creating metrics dataframe
2024-03-24 23:16:07,731:INFO:Initializing Quadratic Discriminant Analysis
2024-03-24 23:16:07,731:INFO:Total runtime is 0.07866926193237304 minutes
2024-03-24 23:16:07,734:INFO:SubProcess create_model() called ==================================
2024-03-24 23:16:07,734:INFO:Initializing create_model()
2024-03-24 23:16:07,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6a3508d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:16:07,735:INFO:Checking exceptions
2024-03-24 23:16:07,735:INFO:Importing libraries
2024-03-24 23:16:07,735:INFO:Copying training dataset
2024-03-24 23:16:07,737:INFO:Defining folds
2024-03-24 23:16:07,737:INFO:Declaring metric variables
2024-03-24 23:16:07,740:INFO:Importing untrained model
2024-03-24 23:16:07,743:INFO:Quadratic Discriminant Analysis Imported successfully
2024-03-24 23:16:07,749:INFO:Starting cross validation
2024-03-24 23:16:07,750:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:16:07,920:INFO:Calculating mean and std
2024-03-24 23:16:07,921:INFO:Creating metrics dataframe
2024-03-24 23:16:07,924:INFO:Uploading results into container
2024-03-24 23:16:07,924:INFO:Uploading model into container now
2024-03-24 23:16:07,924:INFO:_master_model_container: 8
2024-03-24 23:16:07,924:INFO:_display_container: 2
2024-03-24 23:16:07,925:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-03-24 23:16:07,925:INFO:create_model() successfully completed......................................
2024-03-24 23:16:07,988:INFO:SubProcess create_model() end ==================================
2024-03-24 23:16:07,988:INFO:Creating metrics dataframe
2024-03-24 23:16:07,999:INFO:Initializing Ada Boost Classifier
2024-03-24 23:16:07,999:INFO:Total runtime is 0.08312794764836628 minutes
2024-03-24 23:16:08,001:INFO:SubProcess create_model() called ==================================
2024-03-24 23:16:08,002:INFO:Initializing create_model()
2024-03-24 23:16:08,002:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6a3508d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:16:08,002:INFO:Checking exceptions
2024-03-24 23:16:08,002:INFO:Importing libraries
2024-03-24 23:16:08,002:INFO:Copying training dataset
2024-03-24 23:16:08,004:INFO:Defining folds
2024-03-24 23:16:08,004:INFO:Declaring metric variables
2024-03-24 23:16:08,007:INFO:Importing untrained model
2024-03-24 23:16:08,009:INFO:Ada Boost Classifier Imported successfully
2024-03-24 23:16:08,015:INFO:Starting cross validation
2024-03-24 23:16:08,015:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:16:08,855:INFO:Calculating mean and std
2024-03-24 23:16:08,856:INFO:Creating metrics dataframe
2024-03-24 23:16:08,859:INFO:Uploading results into container
2024-03-24 23:16:08,859:INFO:Uploading model into container now
2024-03-24 23:16:08,859:INFO:_master_model_container: 9
2024-03-24 23:16:08,860:INFO:_display_container: 2
2024-03-24 23:16:08,860:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-03-24 23:16:08,860:INFO:create_model() successfully completed......................................
2024-03-24 23:16:08,924:INFO:SubProcess create_model() end ==================================
2024-03-24 23:16:08,924:INFO:Creating metrics dataframe
2024-03-24 23:16:08,934:INFO:Initializing Gradient Boosting Classifier
2024-03-24 23:16:08,934:INFO:Total runtime is 0.09871886571248371 minutes
2024-03-24 23:16:08,937:INFO:SubProcess create_model() called ==================================
2024-03-24 23:16:08,937:INFO:Initializing create_model()
2024-03-24 23:16:08,937:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6a3508d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:16:08,937:INFO:Checking exceptions
2024-03-24 23:16:08,937:INFO:Importing libraries
2024-03-24 23:16:08,937:INFO:Copying training dataset
2024-03-24 23:16:08,940:INFO:Defining folds
2024-03-24 23:16:08,940:INFO:Declaring metric variables
2024-03-24 23:16:08,942:INFO:Importing untrained model
2024-03-24 23:16:08,945:INFO:Gradient Boosting Classifier Imported successfully
2024-03-24 23:16:08,950:INFO:Starting cross validation
2024-03-24 23:16:08,951:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:16:09,762:INFO:Calculating mean and std
2024-03-24 23:16:09,763:INFO:Creating metrics dataframe
2024-03-24 23:16:09,765:INFO:Uploading results into container
2024-03-24 23:16:09,766:INFO:Uploading model into container now
2024-03-24 23:16:09,766:INFO:_master_model_container: 10
2024-03-24 23:16:09,766:INFO:_display_container: 2
2024-03-24 23:16:09,767:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-24 23:16:09,767:INFO:create_model() successfully completed......................................
2024-03-24 23:16:09,831:INFO:SubProcess create_model() end ==================================
2024-03-24 23:16:09,831:INFO:Creating metrics dataframe
2024-03-24 23:16:09,841:INFO:Initializing Linear Discriminant Analysis
2024-03-24 23:16:09,841:INFO:Total runtime is 0.1138369599978129 minutes
2024-03-24 23:16:09,844:INFO:SubProcess create_model() called ==================================
2024-03-24 23:16:09,844:INFO:Initializing create_model()
2024-03-24 23:16:09,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6a3508d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:16:09,844:INFO:Checking exceptions
2024-03-24 23:16:09,844:INFO:Importing libraries
2024-03-24 23:16:09,844:INFO:Copying training dataset
2024-03-24 23:16:09,847:INFO:Defining folds
2024-03-24 23:16:09,847:INFO:Declaring metric variables
2024-03-24 23:16:09,849:INFO:Importing untrained model
2024-03-24 23:16:09,852:INFO:Linear Discriminant Analysis Imported successfully
2024-03-24 23:16:09,857:INFO:Starting cross validation
2024-03-24 23:16:09,858:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:16:10,035:INFO:Calculating mean and std
2024-03-24 23:16:10,036:INFO:Creating metrics dataframe
2024-03-24 23:16:10,038:INFO:Uploading results into container
2024-03-24 23:16:10,039:INFO:Uploading model into container now
2024-03-24 23:16:10,039:INFO:_master_model_container: 11
2024-03-24 23:16:10,039:INFO:_display_container: 2
2024-03-24 23:16:10,039:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-03-24 23:16:10,040:INFO:create_model() successfully completed......................................
2024-03-24 23:16:10,103:INFO:SubProcess create_model() end ==================================
2024-03-24 23:16:10,103:INFO:Creating metrics dataframe
2024-03-24 23:16:10,113:INFO:Initializing Extra Trees Classifier
2024-03-24 23:16:10,113:INFO:Total runtime is 0.11837240854899088 minutes
2024-03-24 23:16:10,116:INFO:SubProcess create_model() called ==================================
2024-03-24 23:16:10,116:INFO:Initializing create_model()
2024-03-24 23:16:10,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6a3508d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:16:10,116:INFO:Checking exceptions
2024-03-24 23:16:10,116:INFO:Importing libraries
2024-03-24 23:16:10,116:INFO:Copying training dataset
2024-03-24 23:16:10,119:INFO:Defining folds
2024-03-24 23:16:10,119:INFO:Declaring metric variables
2024-03-24 23:16:10,121:INFO:Importing untrained model
2024-03-24 23:16:10,124:INFO:Extra Trees Classifier Imported successfully
2024-03-24 23:16:10,129:INFO:Starting cross validation
2024-03-24 23:16:10,130:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:16:12,163:INFO:Calculating mean and std
2024-03-24 23:16:12,164:INFO:Creating metrics dataframe
2024-03-24 23:16:12,168:INFO:Uploading results into container
2024-03-24 23:16:12,168:INFO:Uploading model into container now
2024-03-24 23:16:12,168:INFO:_master_model_container: 12
2024-03-24 23:16:12,169:INFO:_display_container: 2
2024-03-24 23:16:12,169:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-03-24 23:16:12,169:INFO:create_model() successfully completed......................................
2024-03-24 23:16:12,233:INFO:SubProcess create_model() end ==================================
2024-03-24 23:16:12,234:INFO:Creating metrics dataframe
2024-03-24 23:16:12,245:INFO:Initializing Light Gradient Boosting Machine
2024-03-24 23:16:12,245:INFO:Total runtime is 0.1539004325866699 minutes
2024-03-24 23:16:12,248:INFO:SubProcess create_model() called ==================================
2024-03-24 23:16:12,248:INFO:Initializing create_model()
2024-03-24 23:16:12,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6a3508d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:16:12,248:INFO:Checking exceptions
2024-03-24 23:16:12,248:INFO:Importing libraries
2024-03-24 23:16:12,248:INFO:Copying training dataset
2024-03-24 23:16:12,251:INFO:Defining folds
2024-03-24 23:16:12,251:INFO:Declaring metric variables
2024-03-24 23:16:12,254:INFO:Importing untrained model
2024-03-24 23:16:12,257:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-24 23:16:12,262:INFO:Starting cross validation
2024-03-24 23:16:12,263:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:16:12,370:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 345
2024-03-24 23:16:12,576:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.206210 seconds.
2024-03-24 23:16:12,577:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:16:12,577:INFO:[LightGBM] [Info] Total Bins 71
2024-03-24 23:16:12,589:INFO:[LightGBM] [Info] Number of data points in the train set: 560, number of used features: 4
2024-03-24 23:16:12,673:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383929 -> initscore=-0.472906
2024-03-24 23:16:12,673:INFO:[LightGBM] [Info] Start training from score -0.472906
2024-03-24 23:16:12,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:12,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:12,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:12,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:12,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:12,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:12,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:12,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:13,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,099:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 345
2024-03-24 23:16:14,099:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.
2024-03-24 23:16:14,099:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:16:14,099:INFO:[LightGBM] [Info] Total Bins 71
2024-03-24 23:16:14,100:INFO:[LightGBM] [Info] Number of data points in the train set: 560, number of used features: 4
2024-03-24 23:16:14,100:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383929 -> initscore=-0.472906
2024-03-24 23:16:14,100:INFO:[LightGBM] [Info] Start training from score -0.472906
2024-03-24 23:16:14,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:14,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,378:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 345
2024-03-24 23:16:15,379:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.
2024-03-24 23:16:15,379:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:16:15,379:INFO:[LightGBM] [Info] Total Bins 69
2024-03-24 23:16:15,379:INFO:[LightGBM] [Info] Number of data points in the train set: 560, number of used features: 4
2024-03-24 23:16:15,379:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383929 -> initscore=-0.472906
2024-03-24 23:16:15,379:INFO:[LightGBM] [Info] Start training from score -0.472906
2024-03-24 23:16:15,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:15,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,586:INFO:[LightGBM] [Info] Number of positive: 216, number of negative: 345
2024-03-24 23:16:16,586:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.
2024-03-24 23:16:16,587:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:16:16,587:INFO:[LightGBM] [Info] Total Bins 70
2024-03-24 23:16:16,587:INFO:[LightGBM] [Info] Number of data points in the train set: 561, number of used features: 4
2024-03-24 23:16:16,587:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.385027 -> initscore=-0.468266
2024-03-24 23:16:16,587:INFO:[LightGBM] [Info] Start training from score -0.468266
2024-03-24 23:16:16,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:16,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,782:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 346
2024-03-24 23:16:17,782:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.
2024-03-24 23:16:17,782:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:16:17,782:INFO:[LightGBM] [Info] Total Bins 68
2024-03-24 23:16:17,783:INFO:[LightGBM] [Info] Number of data points in the train set: 561, number of used features: 4
2024-03-24 23:16:17,783:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383244 -> initscore=-0.475801
2024-03-24 23:16:17,783:INFO:[LightGBM] [Info] Start training from score -0.475801
2024-03-24 23:16:17,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:17,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:18,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,177:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 346
2024-03-24 23:16:19,177:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.
2024-03-24 23:16:19,177:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:16:19,177:INFO:[LightGBM] [Info] Total Bins 69
2024-03-24 23:16:19,177:INFO:[LightGBM] [Info] Number of data points in the train set: 561, number of used features: 4
2024-03-24 23:16:19,178:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383244 -> initscore=-0.475801
2024-03-24 23:16:19,178:INFO:[LightGBM] [Info] Start training from score -0.475801
2024-03-24 23:16:19,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:19,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,294:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 346
2024-03-24 23:16:20,295:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000341 seconds.
2024-03-24 23:16:20,295:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:16:20,295:INFO:[LightGBM] [Info] Total Bins 69
2024-03-24 23:16:20,295:INFO:[LightGBM] [Info] Number of data points in the train set: 561, number of used features: 4
2024-03-24 23:16:20,295:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383244 -> initscore=-0.475801
2024-03-24 23:16:20,295:INFO:[LightGBM] [Info] Start training from score -0.475801
2024-03-24 23:16:20,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:20,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,491:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 346
2024-03-24 23:16:21,492:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2024-03-24 23:16:21,492:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:16:21,492:INFO:[LightGBM] [Info] Total Bins 69
2024-03-24 23:16:21,492:INFO:[LightGBM] [Info] Number of data points in the train set: 561, number of used features: 4
2024-03-24 23:16:21,492:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383244 -> initscore=-0.475801
2024-03-24 23:16:21,492:INFO:[LightGBM] [Info] Start training from score -0.475801
2024-03-24 23:16:21,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:21,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,685:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 346
2024-03-24 23:16:22,686:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.
2024-03-24 23:16:22,686:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:16:22,686:INFO:[LightGBM] [Info] Total Bins 69
2024-03-24 23:16:22,686:INFO:[LightGBM] [Info] Number of data points in the train set: 561, number of used features: 4
2024-03-24 23:16:22,686:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383244 -> initscore=-0.475801
2024-03-24 23:16:22,686:INFO:[LightGBM] [Info] Start training from score -0.475801
2024-03-24 23:16:22,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:22,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,890:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 346
2024-03-24 23:16:23,891:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.
2024-03-24 23:16:23,891:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:16:23,891:INFO:[LightGBM] [Info] Total Bins 71
2024-03-24 23:16:23,891:INFO:[LightGBM] [Info] Number of data points in the train set: 561, number of used features: 4
2024-03-24 23:16:23,891:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383244 -> initscore=-0.475801
2024-03-24 23:16:23,891:INFO:[LightGBM] [Info] Start training from score -0.475801
2024-03-24 23:16:23,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:23,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:16:24,995:INFO:Calculating mean and std
2024-03-24 23:16:24,997:INFO:Creating metrics dataframe
2024-03-24 23:16:25,000:INFO:Uploading results into container
2024-03-24 23:16:25,071:INFO:Uploading model into container now
2024-03-24 23:16:25,071:INFO:_master_model_container: 13
2024-03-24 23:16:25,071:INFO:_display_container: 2
2024-03-24 23:16:25,072:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-24 23:16:25,072:INFO:create_model() successfully completed......................................
2024-03-24 23:16:25,142:INFO:SubProcess create_model() end ==================================
2024-03-24 23:16:25,142:INFO:Creating metrics dataframe
2024-03-24 23:16:25,153:INFO:Initializing Dummy Classifier
2024-03-24 23:16:25,153:INFO:Total runtime is 0.36903265317281086 minutes
2024-03-24 23:16:25,156:INFO:SubProcess create_model() called ==================================
2024-03-24 23:16:25,156:INFO:Initializing create_model()
2024-03-24 23:16:25,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6a3508d60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:16:25,156:INFO:Checking exceptions
2024-03-24 23:16:25,156:INFO:Importing libraries
2024-03-24 23:16:25,156:INFO:Copying training dataset
2024-03-24 23:16:25,160:INFO:Defining folds
2024-03-24 23:16:25,160:INFO:Declaring metric variables
2024-03-24 23:16:25,163:INFO:Importing untrained model
2024-03-24 23:16:25,166:INFO:Dummy Classifier Imported successfully
2024-03-24 23:16:25,171:INFO:Starting cross validation
2024-03-24 23:16:25,172:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:16:25,186:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:16:25,200:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:16:25,215:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:16:25,229:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:16:25,243:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:16:25,257:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:16:25,272:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:16:25,286:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:16:25,301:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:16:25,315:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:16:25,318:INFO:Calculating mean and std
2024-03-24 23:16:25,319:INFO:Creating metrics dataframe
2024-03-24 23:16:25,322:INFO:Uploading results into container
2024-03-24 23:16:25,322:INFO:Uploading model into container now
2024-03-24 23:16:25,323:INFO:_master_model_container: 14
2024-03-24 23:16:25,323:INFO:_display_container: 2
2024-03-24 23:16:25,323:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-03-24 23:16:25,323:INFO:create_model() successfully completed......................................
2024-03-24 23:16:25,388:INFO:SubProcess create_model() end ==================================
2024-03-24 23:16:25,388:INFO:Creating metrics dataframe
2024-03-24 23:16:25,407:INFO:Initializing create_model()
2024-03-24 23:16:25,407:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb60301dd90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:16:25,407:INFO:Checking exceptions
2024-03-24 23:16:25,408:INFO:Importing libraries
2024-03-24 23:16:25,408:INFO:Copying training dataset
2024-03-24 23:16:25,411:INFO:Defining folds
2024-03-24 23:16:25,411:INFO:Declaring metric variables
2024-03-24 23:16:25,411:INFO:Importing untrained model
2024-03-24 23:16:25,411:INFO:Declaring custom model
2024-03-24 23:16:25,412:INFO:Gradient Boosting Classifier Imported successfully
2024-03-24 23:16:25,412:INFO:Cross validation set to False
2024-03-24 23:16:25,412:INFO:Fitting Model
2024-03-24 23:16:25,483:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-24 23:16:25,483:INFO:create_model() successfully completed......................................
2024-03-24 23:16:25,573:INFO:_master_model_container: 14
2024-03-24 23:16:25,574:INFO:_display_container: 2
2024-03-24 23:16:25,574:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-24 23:16:25,574:INFO:compare_models() successfully completed......................................
2024-03-24 23:23:57,420:INFO:PyCaret ClassificationExperiment
2024-03-24 23:23:57,420:INFO:Logging name: clf-default-name
2024-03-24 23:23:57,420:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-24 23:23:57,420:INFO:version 3.2.0
2024-03-24 23:23:57,420:INFO:Initializing setup()
2024-03-24 23:23:57,420:INFO:self.USI: 58d4
2024-03-24 23:23:57,420:INFO:self._variable_keys: {'is_multiclass', 'logging_param', 'fix_imbalance', 'fold_shuffle_param', 'html_param', '_ml_usecase', 'y_train', 'USI', 'y_test', 'seed', '_available_plots', 'X', 'target_param', 'pipeline', 'memory', 'idx', 'X_test', 'data', 'fold_groups_param', 'log_plots_param', 'X_train', 'exp_name_log', 'n_jobs_param', 'gpu_n_jobs_param', 'exp_id', 'y', 'fold_generator', 'gpu_param'}
2024-03-24 23:23:57,420:INFO:Checking environment
2024-03-24 23:23:57,420:INFO:python_version: 3.8.19
2024-03-24 23:23:57,420:INFO:python_build: ('default', 'Mar 20 2024 19:58:24')
2024-03-24 23:23:57,420:INFO:machine: x86_64
2024-03-24 23:23:57,421:INFO:platform: Linux-5.15.0-1044-nvidia-x86_64-with-glibc2.17
2024-03-24 23:23:57,421:INFO:Memory: svmem(total=540860575744, available=470414352384, percent=13.0, used=66883608576, free=111833673728, active=130979209216, inactive=269580345344, buffers=9814007808, cached=352329285632, shared=41623552, slab=25448009728)
2024-03-24 23:23:57,425:INFO:Physical Core: 64
2024-03-24 23:23:57,425:INFO:Logical Core: 128
2024-03-24 23:23:57,425:INFO:Checking libraries
2024-03-24 23:23:57,425:INFO:System:
2024-03-24 23:23:57,425:INFO:    python: 3.8.19 (default, Mar 20 2024, 19:58:24)  [GCC 11.2.0]
2024-03-24 23:23:57,425:INFO:executable: /root/anaconda3/envs/pc/bin/python
2024-03-24 23:23:57,425:INFO:   machine: Linux-5.15.0-1044-nvidia-x86_64-with-glibc2.17
2024-03-24 23:23:57,425:INFO:PyCaret required dependencies:
2024-03-24 23:23:57,425:INFO:                 pip: 23.3.1
2024-03-24 23:23:57,425:INFO:          setuptools: 68.2.2
2024-03-24 23:23:57,425:INFO:             pycaret: 3.2.0
2024-03-24 23:23:57,425:INFO:             IPython: 8.12.0
2024-03-24 23:23:57,425:INFO:          ipywidgets: 8.1.2
2024-03-24 23:23:57,425:INFO:                tqdm: 4.66.2
2024-03-24 23:23:57,425:INFO:               numpy: 1.24.4
2024-03-24 23:23:57,425:INFO:              pandas: 1.5.3
2024-03-24 23:23:57,425:INFO:              jinja2: 3.1.3
2024-03-24 23:23:57,425:INFO:               scipy: 1.10.1
2024-03-24 23:23:57,425:INFO:              joblib: 1.3.2
2024-03-24 23:23:57,425:INFO:             sklearn: 1.2.2
2024-03-24 23:23:57,425:INFO:                pyod: 1.1.3
2024-03-24 23:23:57,425:INFO:            imblearn: 0.12.0
2024-03-24 23:23:57,425:INFO:   category_encoders: 2.6.3
2024-03-24 23:23:57,425:INFO:            lightgbm: 4.3.0
2024-03-24 23:23:57,425:INFO:               numba: 0.58.1
2024-03-24 23:23:57,425:INFO:            requests: 2.31.0
2024-03-24 23:23:57,425:INFO:          matplotlib: 3.6.0
2024-03-24 23:23:57,425:INFO:          scikitplot: 0.3.7
2024-03-24 23:23:57,425:INFO:         yellowbrick: 1.5
2024-03-24 23:23:57,425:INFO:              plotly: 5.20.0
2024-03-24 23:23:57,425:INFO:    plotly-resampler: Not installed
2024-03-24 23:23:57,425:INFO:             kaleido: 0.2.1
2024-03-24 23:23:57,425:INFO:           schemdraw: 0.15
2024-03-24 23:23:57,425:INFO:         statsmodels: 0.14.1
2024-03-24 23:23:57,426:INFO:              sktime: 0.21.1
2024-03-24 23:23:57,426:INFO:               tbats: 1.1.3
2024-03-24 23:23:57,426:INFO:            pmdarima: 2.0.4
2024-03-24 23:23:57,426:INFO:              psutil: 5.9.8
2024-03-24 23:23:57,426:INFO:          markupsafe: 2.1.3
2024-03-24 23:23:57,426:INFO:             pickle5: Not installed
2024-03-24 23:23:57,426:INFO:         cloudpickle: 3.0.0
2024-03-24 23:23:57,426:INFO:         deprecation: 2.1.0
2024-03-24 23:23:57,426:INFO:              xxhash: 3.4.1
2024-03-24 23:23:57,426:INFO:           wurlitzer: 3.0.3
2024-03-24 23:23:57,426:INFO:PyCaret optional dependencies:
2024-03-24 23:23:57,426:INFO:                shap: Not installed
2024-03-24 23:23:57,426:INFO:           interpret: Not installed
2024-03-24 23:23:57,426:INFO:                umap: Not installed
2024-03-24 23:23:57,426:INFO:     ydata_profiling: Not installed
2024-03-24 23:23:57,426:INFO:  explainerdashboard: Not installed
2024-03-24 23:23:57,426:INFO:             autoviz: Not installed
2024-03-24 23:23:57,426:INFO:           fairlearn: Not installed
2024-03-24 23:23:57,426:INFO:          deepchecks: Not installed
2024-03-24 23:23:57,426:INFO:             xgboost: Not installed
2024-03-24 23:23:57,426:INFO:            catboost: Not installed
2024-03-24 23:23:57,426:INFO:              kmodes: Not installed
2024-03-24 23:23:57,426:INFO:             mlxtend: Not installed
2024-03-24 23:23:57,426:INFO:       statsforecast: Not installed
2024-03-24 23:23:57,426:INFO:        tune_sklearn: Not installed
2024-03-24 23:23:57,426:INFO:                 ray: Not installed
2024-03-24 23:23:57,426:INFO:            hyperopt: Not installed
2024-03-24 23:23:57,426:INFO:              optuna: Not installed
2024-03-24 23:23:57,426:INFO:               skopt: Not installed
2024-03-24 23:23:57,426:INFO:              mlflow: Not installed
2024-03-24 23:23:57,426:INFO:              gradio: Not installed
2024-03-24 23:23:57,426:INFO:             fastapi: Not installed
2024-03-24 23:23:57,426:INFO:             uvicorn: Not installed
2024-03-24 23:23:57,426:INFO:              m2cgen: Not installed
2024-03-24 23:23:57,426:INFO:           evidently: Not installed
2024-03-24 23:23:57,426:INFO:               fugue: Not installed
2024-03-24 23:23:57,426:INFO:           streamlit: Not installed
2024-03-24 23:23:57,426:INFO:             prophet: Not installed
2024-03-24 23:23:57,426:INFO:None
2024-03-24 23:23:57,426:INFO:Set up GPU usage.
2024-03-24 23:23:57,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,426:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-03-24 23:23:57,427:INFO:Set up data.
2024-03-24 23:23:57,430:INFO:Set up folding strategy.
2024-03-24 23:23:57,430:INFO:Set up train/test split.
2024-03-24 23:23:57,433:INFO:Set up index.
2024-03-24 23:23:57,433:INFO:Assigning column types.
2024-03-24 23:23:57,435:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-24 23:23:57,436:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,482:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-24 23:23:57,482:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,483:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-24 23:23:57,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,511:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,512:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:23:57,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:23:57,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,566:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-24 23:23:57,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,566:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-24 23:23:57,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,590:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,595:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:23:57,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:23:57,600:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-24 23:23:57,600:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,648:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,648:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,649:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-24 23:23:57,649:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,672:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,677:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,678:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:23:57,682:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:23:57,682:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,731:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-24 23:23:57,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,755:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,761:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:23:57,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:23:57,767:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-24 23:23:57,767:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:23:57,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:23:57,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,897:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,897:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,926:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:57,927:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:23:57,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:23:57,932:INFO:Preparing preprocessing pipeline...
2024-03-24 23:23:57,933:INFO:Set up simple imputation.
2024-03-24 23:23:57,946:INFO:Finished creating preprocessing pipeline.
2024-03-24 23:23:57,949:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'SibSp', 'Age', 'Sex'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2024-03-24 23:23:57,949:INFO:Creating final display dataframe.
2024-03-24 23:23:57,995:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 5)
4        Transformed data shape          (891, 5)
5   Transformed train set shape          (623, 5)
6    Transformed test set shape          (268, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              58d4
2024-03-24 23:23:58,000:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:58,047:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:58,047:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:58,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:58,071:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:58,076:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:58,076:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:23:58,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:23:58,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:58,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:58,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:58,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:58,153:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:58,158:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-24 23:23:58,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:23:58,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-24 23:23:58,164:INFO:setup() successfully completed in 0.75s...............
2024-03-24 23:23:58,164:INFO:Initializing compare_models()
2024-03-24 23:23:58,164:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-03-24 23:23:58,164:INFO:Checking exceptions
2024-03-24 23:23:58,167:INFO:Preparing display monitor
2024-03-24 23:23:58,187:INFO:Initializing Logistic Regression
2024-03-24 23:23:58,187:INFO:Total runtime is 1.1920928955078125e-06 minutes
2024-03-24 23:23:58,189:INFO:SubProcess create_model() called ==================================
2024-03-24 23:23:58,189:INFO:Initializing create_model()
2024-03-24 23:23:58,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6aac3b070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:23:58,190:INFO:Checking exceptions
2024-03-24 23:23:58,190:INFO:Importing libraries
2024-03-24 23:23:58,190:INFO:Copying training dataset
2024-03-24 23:23:58,192:INFO:Defining folds
2024-03-24 23:23:58,192:INFO:Declaring metric variables
2024-03-24 23:23:58,195:INFO:Importing untrained model
2024-03-24 23:23:58,198:INFO:Logistic Regression Imported successfully
2024-03-24 23:23:58,203:INFO:Starting cross validation
2024-03-24 23:23:58,204:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:23:58,416:INFO:Calculating mean and std
2024-03-24 23:23:58,417:INFO:Creating metrics dataframe
2024-03-24 23:23:58,419:INFO:Uploading results into container
2024-03-24 23:23:58,420:INFO:Uploading model into container now
2024-03-24 23:23:58,420:INFO:_master_model_container: 1
2024-03-24 23:23:58,420:INFO:_display_container: 2
2024-03-24 23:23:58,420:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-03-24 23:23:58,420:INFO:create_model() successfully completed......................................
2024-03-24 23:23:58,497:INFO:SubProcess create_model() end ==================================
2024-03-24 23:23:58,497:INFO:Creating metrics dataframe
2024-03-24 23:23:58,505:INFO:Initializing K Neighbors Classifier
2024-03-24 23:23:58,505:INFO:Total runtime is 0.005300859610239665 minutes
2024-03-24 23:23:58,507:INFO:SubProcess create_model() called ==================================
2024-03-24 23:23:58,508:INFO:Initializing create_model()
2024-03-24 23:23:58,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6aac3b070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:23:58,508:INFO:Checking exceptions
2024-03-24 23:23:58,508:INFO:Importing libraries
2024-03-24 23:23:58,508:INFO:Copying training dataset
2024-03-24 23:23:58,510:INFO:Defining folds
2024-03-24 23:23:58,510:INFO:Declaring metric variables
2024-03-24 23:23:58,513:INFO:Importing untrained model
2024-03-24 23:23:58,515:INFO:K Neighbors Classifier Imported successfully
2024-03-24 23:23:58,520:INFO:Starting cross validation
2024-03-24 23:23:58,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:23:59,284:INFO:Calculating mean and std
2024-03-24 23:23:59,286:INFO:Creating metrics dataframe
2024-03-24 23:23:59,289:INFO:Uploading results into container
2024-03-24 23:23:59,289:INFO:Uploading model into container now
2024-03-24 23:23:59,289:INFO:_master_model_container: 2
2024-03-24 23:23:59,289:INFO:_display_container: 2
2024-03-24 23:23:59,290:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-03-24 23:23:59,290:INFO:create_model() successfully completed......................................
2024-03-24 23:23:59,356:INFO:SubProcess create_model() end ==================================
2024-03-24 23:23:59,356:INFO:Creating metrics dataframe
2024-03-24 23:23:59,366:INFO:Initializing Naive Bayes
2024-03-24 23:23:59,366:INFO:Total runtime is 0.019652752081553142 minutes
2024-03-24 23:23:59,369:INFO:SubProcess create_model() called ==================================
2024-03-24 23:23:59,369:INFO:Initializing create_model()
2024-03-24 23:23:59,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6aac3b070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:23:59,369:INFO:Checking exceptions
2024-03-24 23:23:59,369:INFO:Importing libraries
2024-03-24 23:23:59,369:INFO:Copying training dataset
2024-03-24 23:23:59,372:INFO:Defining folds
2024-03-24 23:23:59,372:INFO:Declaring metric variables
2024-03-24 23:23:59,375:INFO:Importing untrained model
2024-03-24 23:23:59,377:INFO:Naive Bayes Imported successfully
2024-03-24 23:23:59,383:INFO:Starting cross validation
2024-03-24 23:23:59,384:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:23:59,550:INFO:Calculating mean and std
2024-03-24 23:23:59,551:INFO:Creating metrics dataframe
2024-03-24 23:23:59,553:INFO:Uploading results into container
2024-03-24 23:23:59,554:INFO:Uploading model into container now
2024-03-24 23:23:59,554:INFO:_master_model_container: 3
2024-03-24 23:23:59,554:INFO:_display_container: 2
2024-03-24 23:23:59,554:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-03-24 23:23:59,554:INFO:create_model() successfully completed......................................
2024-03-24 23:23:59,620:INFO:SubProcess create_model() end ==================================
2024-03-24 23:23:59,620:INFO:Creating metrics dataframe
2024-03-24 23:23:59,629:INFO:Initializing Decision Tree Classifier
2024-03-24 23:23:59,629:INFO:Total runtime is 0.024037082990010582 minutes
2024-03-24 23:23:59,631:INFO:SubProcess create_model() called ==================================
2024-03-24 23:23:59,632:INFO:Initializing create_model()
2024-03-24 23:23:59,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6aac3b070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:23:59,632:INFO:Checking exceptions
2024-03-24 23:23:59,632:INFO:Importing libraries
2024-03-24 23:23:59,632:INFO:Copying training dataset
2024-03-24 23:23:59,634:INFO:Defining folds
2024-03-24 23:23:59,634:INFO:Declaring metric variables
2024-03-24 23:23:59,637:INFO:Importing untrained model
2024-03-24 23:23:59,640:INFO:Decision Tree Classifier Imported successfully
2024-03-24 23:23:59,644:INFO:Starting cross validation
2024-03-24 23:23:59,645:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:23:59,814:INFO:Calculating mean and std
2024-03-24 23:23:59,815:INFO:Creating metrics dataframe
2024-03-24 23:23:59,817:INFO:Uploading results into container
2024-03-24 23:23:59,818:INFO:Uploading model into container now
2024-03-24 23:23:59,818:INFO:_master_model_container: 4
2024-03-24 23:23:59,818:INFO:_display_container: 2
2024-03-24 23:23:59,818:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-03-24 23:23:59,819:INFO:create_model() successfully completed......................................
2024-03-24 23:23:59,884:INFO:SubProcess create_model() end ==================================
2024-03-24 23:23:59,884:INFO:Creating metrics dataframe
2024-03-24 23:23:59,893:INFO:Initializing SVM - Linear Kernel
2024-03-24 23:23:59,893:INFO:Total runtime is 0.02843827803929647 minutes
2024-03-24 23:23:59,896:INFO:SubProcess create_model() called ==================================
2024-03-24 23:23:59,896:INFO:Initializing create_model()
2024-03-24 23:23:59,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6aac3b070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:23:59,896:INFO:Checking exceptions
2024-03-24 23:23:59,896:INFO:Importing libraries
2024-03-24 23:23:59,896:INFO:Copying training dataset
2024-03-24 23:23:59,898:INFO:Defining folds
2024-03-24 23:23:59,899:INFO:Declaring metric variables
2024-03-24 23:23:59,901:INFO:Importing untrained model
2024-03-24 23:23:59,904:INFO:SVM - Linear Kernel Imported successfully
2024-03-24 23:23:59,909:INFO:Starting cross validation
2024-03-24 23:23:59,910:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:23:59,922:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:23:59,939:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:23:59,956:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:23:59,971:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:23:59,987:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:24:00,003:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:24:00,019:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:24:00,035:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:24:00,051:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:24:00,067:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-03-24 23:24:00,073:INFO:Calculating mean and std
2024-03-24 23:24:00,074:INFO:Creating metrics dataframe
2024-03-24 23:24:00,077:INFO:Uploading results into container
2024-03-24 23:24:00,077:INFO:Uploading model into container now
2024-03-24 23:24:00,077:INFO:_master_model_container: 5
2024-03-24 23:24:00,077:INFO:_display_container: 2
2024-03-24 23:24:00,078:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-03-24 23:24:00,078:INFO:create_model() successfully completed......................................
2024-03-24 23:24:00,143:INFO:SubProcess create_model() end ==================================
2024-03-24 23:24:00,143:INFO:Creating metrics dataframe
2024-03-24 23:24:00,152:INFO:Initializing Ridge Classifier
2024-03-24 23:24:00,152:INFO:Total runtime is 0.03276341756184896 minutes
2024-03-24 23:24:00,155:INFO:SubProcess create_model() called ==================================
2024-03-24 23:24:00,156:INFO:Initializing create_model()
2024-03-24 23:24:00,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6aac3b070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:24:00,156:INFO:Checking exceptions
2024-03-24 23:24:00,156:INFO:Importing libraries
2024-03-24 23:24:00,156:INFO:Copying training dataset
2024-03-24 23:24:00,158:INFO:Defining folds
2024-03-24 23:24:00,158:INFO:Declaring metric variables
2024-03-24 23:24:00,161:INFO:Importing untrained model
2024-03-24 23:24:00,163:INFO:Ridge Classifier Imported successfully
2024-03-24 23:24:00,169:INFO:Starting cross validation
2024-03-24 23:24:00,169:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:24:00,181:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:24:00,197:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:24:00,213:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:24:00,228:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:24:00,244:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:24:00,259:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:24:00,275:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:24:00,291:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:24:00,306:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:24:00,322:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/root/anaconda3/envs/pc/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-03-24 23:24:00,328:INFO:Calculating mean and std
2024-03-24 23:24:00,329:INFO:Creating metrics dataframe
2024-03-24 23:24:00,331:INFO:Uploading results into container
2024-03-24 23:24:00,332:INFO:Uploading model into container now
2024-03-24 23:24:00,332:INFO:_master_model_container: 6
2024-03-24 23:24:00,332:INFO:_display_container: 2
2024-03-24 23:24:00,332:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-03-24 23:24:00,332:INFO:create_model() successfully completed......................................
2024-03-24 23:24:00,398:INFO:SubProcess create_model() end ==================================
2024-03-24 23:24:00,398:INFO:Creating metrics dataframe
2024-03-24 23:24:00,407:INFO:Initializing Random Forest Classifier
2024-03-24 23:24:00,407:INFO:Total runtime is 0.037010443210601804 minutes
2024-03-24 23:24:00,410:INFO:SubProcess create_model() called ==================================
2024-03-24 23:24:00,410:INFO:Initializing create_model()
2024-03-24 23:24:00,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6aac3b070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:24:00,410:INFO:Checking exceptions
2024-03-24 23:24:00,410:INFO:Importing libraries
2024-03-24 23:24:00,410:INFO:Copying training dataset
2024-03-24 23:24:00,413:INFO:Defining folds
2024-03-24 23:24:00,413:INFO:Declaring metric variables
2024-03-24 23:24:00,415:INFO:Importing untrained model
2024-03-24 23:24:00,418:INFO:Random Forest Classifier Imported successfully
2024-03-24 23:24:00,423:INFO:Starting cross validation
2024-03-24 23:24:00,424:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:24:02,794:INFO:Calculating mean and std
2024-03-24 23:24:02,795:INFO:Creating metrics dataframe
2024-03-24 23:24:02,798:INFO:Uploading results into container
2024-03-24 23:24:02,798:INFO:Uploading model into container now
2024-03-24 23:24:02,799:INFO:_master_model_container: 7
2024-03-24 23:24:02,799:INFO:_display_container: 2
2024-03-24 23:24:02,799:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-03-24 23:24:02,799:INFO:create_model() successfully completed......................................
2024-03-24 23:24:02,866:INFO:SubProcess create_model() end ==================================
2024-03-24 23:24:02,866:INFO:Creating metrics dataframe
2024-03-24 23:24:02,876:INFO:Initializing Quadratic Discriminant Analysis
2024-03-24 23:24:02,876:INFO:Total runtime is 0.07815546592076619 minutes
2024-03-24 23:24:02,879:INFO:SubProcess create_model() called ==================================
2024-03-24 23:24:02,879:INFO:Initializing create_model()
2024-03-24 23:24:02,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6aac3b070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:24:02,879:INFO:Checking exceptions
2024-03-24 23:24:02,879:INFO:Importing libraries
2024-03-24 23:24:02,879:INFO:Copying training dataset
2024-03-24 23:24:02,882:INFO:Defining folds
2024-03-24 23:24:02,882:INFO:Declaring metric variables
2024-03-24 23:24:02,884:INFO:Importing untrained model
2024-03-24 23:24:02,887:INFO:Quadratic Discriminant Analysis Imported successfully
2024-03-24 23:24:02,893:INFO:Starting cross validation
2024-03-24 23:24:02,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:24:03,063:INFO:Calculating mean and std
2024-03-24 23:24:03,064:INFO:Creating metrics dataframe
2024-03-24 23:24:03,066:INFO:Uploading results into container
2024-03-24 23:24:03,067:INFO:Uploading model into container now
2024-03-24 23:24:03,067:INFO:_master_model_container: 8
2024-03-24 23:24:03,067:INFO:_display_container: 2
2024-03-24 23:24:03,067:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-03-24 23:24:03,067:INFO:create_model() successfully completed......................................
2024-03-24 23:24:03,133:INFO:SubProcess create_model() end ==================================
2024-03-24 23:24:03,133:INFO:Creating metrics dataframe
2024-03-24 23:24:03,143:INFO:Initializing Ada Boost Classifier
2024-03-24 23:24:03,144:INFO:Total runtime is 0.0826163371404012 minutes
2024-03-24 23:24:03,146:INFO:SubProcess create_model() called ==================================
2024-03-24 23:24:03,147:INFO:Initializing create_model()
2024-03-24 23:24:03,147:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6aac3b070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:24:03,147:INFO:Checking exceptions
2024-03-24 23:24:03,147:INFO:Importing libraries
2024-03-24 23:24:03,147:INFO:Copying training dataset
2024-03-24 23:24:03,150:INFO:Defining folds
2024-03-24 23:24:03,150:INFO:Declaring metric variables
2024-03-24 23:24:03,152:INFO:Importing untrained model
2024-03-24 23:24:03,155:INFO:Ada Boost Classifier Imported successfully
2024-03-24 23:24:03,160:INFO:Starting cross validation
2024-03-24 23:24:03,160:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:24:03,990:INFO:Calculating mean and std
2024-03-24 23:24:03,991:INFO:Creating metrics dataframe
2024-03-24 23:24:03,994:INFO:Uploading results into container
2024-03-24 23:24:03,994:INFO:Uploading model into container now
2024-03-24 23:24:03,994:INFO:_master_model_container: 9
2024-03-24 23:24:03,995:INFO:_display_container: 2
2024-03-24 23:24:03,995:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-03-24 23:24:03,995:INFO:create_model() successfully completed......................................
2024-03-24 23:24:04,061:INFO:SubProcess create_model() end ==================================
2024-03-24 23:24:04,061:INFO:Creating metrics dataframe
2024-03-24 23:24:04,071:INFO:Initializing Gradient Boosting Classifier
2024-03-24 23:24:04,071:INFO:Total runtime is 0.09807485342025757 minutes
2024-03-24 23:24:04,074:INFO:SubProcess create_model() called ==================================
2024-03-24 23:24:04,074:INFO:Initializing create_model()
2024-03-24 23:24:04,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6aac3b070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:24:04,074:INFO:Checking exceptions
2024-03-24 23:24:04,074:INFO:Importing libraries
2024-03-24 23:24:04,074:INFO:Copying training dataset
2024-03-24 23:24:04,077:INFO:Defining folds
2024-03-24 23:24:04,077:INFO:Declaring metric variables
2024-03-24 23:24:04,079:INFO:Importing untrained model
2024-03-24 23:24:04,082:INFO:Gradient Boosting Classifier Imported successfully
2024-03-24 23:24:04,087:INFO:Starting cross validation
2024-03-24 23:24:04,088:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:24:04,892:INFO:Calculating mean and std
2024-03-24 23:24:04,893:INFO:Creating metrics dataframe
2024-03-24 23:24:04,896:INFO:Uploading results into container
2024-03-24 23:24:04,896:INFO:Uploading model into container now
2024-03-24 23:24:04,897:INFO:_master_model_container: 10
2024-03-24 23:24:04,897:INFO:_display_container: 2
2024-03-24 23:24:04,897:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-24 23:24:04,897:INFO:create_model() successfully completed......................................
2024-03-24 23:24:04,963:INFO:SubProcess create_model() end ==================================
2024-03-24 23:24:04,963:INFO:Creating metrics dataframe
2024-03-24 23:24:04,974:INFO:Initializing Linear Discriminant Analysis
2024-03-24 23:24:04,974:INFO:Total runtime is 0.11312013069788615 minutes
2024-03-24 23:24:04,977:INFO:SubProcess create_model() called ==================================
2024-03-24 23:24:04,977:INFO:Initializing create_model()
2024-03-24 23:24:04,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6aac3b070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:24:04,977:INFO:Checking exceptions
2024-03-24 23:24:04,977:INFO:Importing libraries
2024-03-24 23:24:04,977:INFO:Copying training dataset
2024-03-24 23:24:04,980:INFO:Defining folds
2024-03-24 23:24:04,980:INFO:Declaring metric variables
2024-03-24 23:24:04,982:INFO:Importing untrained model
2024-03-24 23:24:04,985:INFO:Linear Discriminant Analysis Imported successfully
2024-03-24 23:24:04,990:INFO:Starting cross validation
2024-03-24 23:24:04,991:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:24:05,161:INFO:Calculating mean and std
2024-03-24 23:24:05,162:INFO:Creating metrics dataframe
2024-03-24 23:24:05,165:INFO:Uploading results into container
2024-03-24 23:24:05,165:INFO:Uploading model into container now
2024-03-24 23:24:05,165:INFO:_master_model_container: 11
2024-03-24 23:24:05,165:INFO:_display_container: 2
2024-03-24 23:24:05,165:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-03-24 23:24:05,166:INFO:create_model() successfully completed......................................
2024-03-24 23:24:05,231:INFO:SubProcess create_model() end ==================================
2024-03-24 23:24:05,231:INFO:Creating metrics dataframe
2024-03-24 23:24:05,242:INFO:Initializing Extra Trees Classifier
2024-03-24 23:24:05,242:INFO:Total runtime is 0.11759053866068522 minutes
2024-03-24 23:24:05,245:INFO:SubProcess create_model() called ==================================
2024-03-24 23:24:05,245:INFO:Initializing create_model()
2024-03-24 23:24:05,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6aac3b070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:24:05,245:INFO:Checking exceptions
2024-03-24 23:24:05,245:INFO:Importing libraries
2024-03-24 23:24:05,245:INFO:Copying training dataset
2024-03-24 23:24:05,248:INFO:Defining folds
2024-03-24 23:24:05,248:INFO:Declaring metric variables
2024-03-24 23:24:05,251:INFO:Importing untrained model
2024-03-24 23:24:05,253:INFO:Extra Trees Classifier Imported successfully
2024-03-24 23:24:05,259:INFO:Starting cross validation
2024-03-24 23:24:05,260:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:24:07,298:INFO:Calculating mean and std
2024-03-24 23:24:07,300:INFO:Creating metrics dataframe
2024-03-24 23:24:07,303:INFO:Uploading results into container
2024-03-24 23:24:07,303:INFO:Uploading model into container now
2024-03-24 23:24:07,303:INFO:_master_model_container: 12
2024-03-24 23:24:07,303:INFO:_display_container: 2
2024-03-24 23:24:07,304:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-03-24 23:24:07,304:INFO:create_model() successfully completed......................................
2024-03-24 23:24:07,372:INFO:SubProcess create_model() end ==================================
2024-03-24 23:24:07,373:INFO:Creating metrics dataframe
2024-03-24 23:24:07,384:INFO:Initializing Light Gradient Boosting Machine
2024-03-24 23:24:07,384:INFO:Total runtime is 0.15329043070475262 minutes
2024-03-24 23:24:07,387:INFO:SubProcess create_model() called ==================================
2024-03-24 23:24:07,387:INFO:Initializing create_model()
2024-03-24 23:24:07,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6aac3b070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:24:07,387:INFO:Checking exceptions
2024-03-24 23:24:07,387:INFO:Importing libraries
2024-03-24 23:24:07,387:INFO:Copying training dataset
2024-03-24 23:24:07,390:INFO:Defining folds
2024-03-24 23:24:07,390:INFO:Declaring metric variables
2024-03-24 23:24:07,393:INFO:Importing untrained model
2024-03-24 23:24:07,396:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-24 23:24:07,401:INFO:Starting cross validation
2024-03-24 23:24:07,402:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:24:07,473:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 345
2024-03-24 23:24:07,677:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203517 seconds.
2024-03-24 23:24:07,677:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:24:07,677:INFO:[LightGBM] [Info] Total Bins 71
2024-03-24 23:24:07,689:INFO:[LightGBM] [Info] Number of data points in the train set: 560, number of used features: 4
2024-03-24 23:24:07,776:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383929 -> initscore=-0.472906
2024-03-24 23:24:07,776:INFO:[LightGBM] [Info] Start training from score -0.472906
2024-03-24 23:24:07,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:07,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:08,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,287:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 345
2024-03-24 23:24:09,288:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.
2024-03-24 23:24:09,288:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:24:09,288:INFO:[LightGBM] [Info] Total Bins 71
2024-03-24 23:24:09,288:INFO:[LightGBM] [Info] Number of data points in the train set: 560, number of used features: 4
2024-03-24 23:24:09,288:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383929 -> initscore=-0.472906
2024-03-24 23:24:09,288:INFO:[LightGBM] [Info] Start training from score -0.472906
2024-03-24 23:24:09,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:09,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,479:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 345
2024-03-24 23:24:10,479:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2024-03-24 23:24:10,479:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:24:10,479:INFO:[LightGBM] [Info] Total Bins 69
2024-03-24 23:24:10,480:INFO:[LightGBM] [Info] Number of data points in the train set: 560, number of used features: 4
2024-03-24 23:24:10,480:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383929 -> initscore=-0.472906
2024-03-24 23:24:10,480:INFO:[LightGBM] [Info] Start training from score -0.472906
2024-03-24 23:24:10,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:10,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:11,696:INFO:[LightGBM] [Info] Number of positive: 216, number of negative: 345
2024-03-24 23:24:11,696:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.
2024-03-24 23:24:11,696:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:24:11,696:INFO:[LightGBM] [Info] Total Bins 70
2024-03-24 23:24:11,697:INFO:[LightGBM] [Info] Number of data points in the train set: 561, number of used features: 4
2024-03-24 23:24:11,697:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.385027 -> initscore=-0.468266
2024-03-24 23:24:11,697:INFO:[LightGBM] [Info] Start training from score -0.468266
2024-03-24 23:24:11,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:12,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,987:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 346
2024-03-24 23:24:13,987:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000324 seconds.
2024-03-24 23:24:13,987:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:24:13,988:INFO:[LightGBM] [Info] Total Bins 68
2024-03-24 23:24:13,988:INFO:[LightGBM] [Info] Number of data points in the train set: 561, number of used features: 4
2024-03-24 23:24:13,988:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383244 -> initscore=-0.475801
2024-03-24 23:24:13,988:INFO:[LightGBM] [Info] Start training from score -0.475801
2024-03-24 23:24:13,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:13,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:14,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,388:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 346
2024-03-24 23:24:15,388:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.
2024-03-24 23:24:15,388:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:24:15,388:INFO:[LightGBM] [Info] Total Bins 69
2024-03-24 23:24:15,388:INFO:[LightGBM] [Info] Number of data points in the train set: 561, number of used features: 4
2024-03-24 23:24:15,389:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383244 -> initscore=-0.475801
2024-03-24 23:24:15,389:INFO:[LightGBM] [Info] Start training from score -0.475801
2024-03-24 23:24:15,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:15,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,778:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 346
2024-03-24 23:24:16,778:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000339 seconds.
2024-03-24 23:24:16,778:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:24:16,779:INFO:[LightGBM] [Info] Total Bins 69
2024-03-24 23:24:16,779:INFO:[LightGBM] [Info] Number of data points in the train set: 561, number of used features: 4
2024-03-24 23:24:16,779:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383244 -> initscore=-0.475801
2024-03-24 23:24:16,779:INFO:[LightGBM] [Info] Start training from score -0.475801
2024-03-24 23:24:16,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:16,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:17,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,091:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 346
2024-03-24 23:24:18,092:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.
2024-03-24 23:24:18,092:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:24:18,092:INFO:[LightGBM] [Info] Total Bins 69
2024-03-24 23:24:18,092:INFO:[LightGBM] [Info] Number of data points in the train set: 561, number of used features: 4
2024-03-24 23:24:18,092:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383244 -> initscore=-0.475801
2024-03-24 23:24:18,092:INFO:[LightGBM] [Info] Start training from score -0.475801
2024-03-24 23:24:18,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:18,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,487:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 346
2024-03-24 23:24:19,488:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2024-03-24 23:24:19,488:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:24:19,488:INFO:[LightGBM] [Info] Total Bins 69
2024-03-24 23:24:19,488:INFO:[LightGBM] [Info] Number of data points in the train set: 561, number of used features: 4
2024-03-24 23:24:19,488:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383244 -> initscore=-0.475801
2024-03-24 23:24:19,488:INFO:[LightGBM] [Info] Start training from score -0.475801
2024-03-24 23:24:19,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:19,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,884:INFO:[LightGBM] [Info] Number of positive: 215, number of negative: 346
2024-03-24 23:24:20,885:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000328 seconds.
2024-03-24 23:24:20,885:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-24 23:24:20,885:INFO:[LightGBM] [Info] Total Bins 71
2024-03-24 23:24:20,885:INFO:[LightGBM] [Info] Number of data points in the train set: 561, number of used features: 4
2024-03-24 23:24:20,885:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383244 -> initscore=-0.475801
2024-03-24 23:24:20,885:INFO:[LightGBM] [Info] Start training from score -0.475801
2024-03-24 23:24:20,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:20,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:21,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:22,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:22,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:22,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:22,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:22,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:22,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:22,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:22,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:22,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:22,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:22,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:22,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:22,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:22,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-03-24 23:24:22,279:INFO:Calculating mean and std
2024-03-24 23:24:22,281:INFO:Creating metrics dataframe
2024-03-24 23:24:22,284:INFO:Uploading results into container
2024-03-24 23:24:22,284:INFO:Uploading model into container now
2024-03-24 23:24:22,285:INFO:_master_model_container: 13
2024-03-24 23:24:22,285:INFO:_display_container: 2
2024-03-24 23:24:22,285:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-24 23:24:22,285:INFO:create_model() successfully completed......................................
2024-03-24 23:24:22,367:INFO:SubProcess create_model() end ==================================
2024-03-24 23:24:22,367:INFO:Creating metrics dataframe
2024-03-24 23:24:22,378:INFO:Initializing Dummy Classifier
2024-03-24 23:24:22,378:INFO:Total runtime is 0.403194785118103 minutes
2024-03-24 23:24:22,381:INFO:SubProcess create_model() called ==================================
2024-03-24 23:24:22,381:INFO:Initializing create_model()
2024-03-24 23:24:22,381:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb6aac3b070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:24:22,381:INFO:Checking exceptions
2024-03-24 23:24:22,381:INFO:Importing libraries
2024-03-24 23:24:22,381:INFO:Copying training dataset
2024-03-24 23:24:22,384:INFO:Defining folds
2024-03-24 23:24:22,384:INFO:Declaring metric variables
2024-03-24 23:24:22,387:INFO:Importing untrained model
2024-03-24 23:24:22,389:INFO:Dummy Classifier Imported successfully
2024-03-24 23:24:22,394:INFO:Starting cross validation
2024-03-24 23:24:22,395:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-03-24 23:24:22,408:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:24:22,422:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:24:22,437:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:24:22,451:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:24:22,465:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:24:22,479:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:24:22,494:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:24:22,508:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:24:22,522:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:24:22,537:WARNING:/root/anaconda3/envs/pc/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-03-24 23:24:22,540:INFO:Calculating mean and std
2024-03-24 23:24:22,541:INFO:Creating metrics dataframe
2024-03-24 23:24:22,544:INFO:Uploading results into container
2024-03-24 23:24:22,544:INFO:Uploading model into container now
2024-03-24 23:24:22,544:INFO:_master_model_container: 14
2024-03-24 23:24:22,544:INFO:_display_container: 2
2024-03-24 23:24:22,544:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-03-24 23:24:22,544:INFO:create_model() successfully completed......................................
2024-03-24 23:24:22,612:INFO:SubProcess create_model() end ==================================
2024-03-24 23:24:22,612:INFO:Creating metrics dataframe
2024-03-24 23:24:22,630:INFO:Initializing create_model()
2024-03-24 23:24:22,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb5fb90f400>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-24 23:24:22,630:INFO:Checking exceptions
2024-03-24 23:24:22,632:INFO:Importing libraries
2024-03-24 23:24:22,632:INFO:Copying training dataset
2024-03-24 23:24:22,634:INFO:Defining folds
2024-03-24 23:24:22,634:INFO:Declaring metric variables
2024-03-24 23:24:22,634:INFO:Importing untrained model
2024-03-24 23:24:22,634:INFO:Declaring custom model
2024-03-24 23:24:22,635:INFO:Gradient Boosting Classifier Imported successfully
2024-03-24 23:24:22,636:INFO:Cross validation set to False
2024-03-24 23:24:22,636:INFO:Fitting Model
2024-03-24 23:24:22,708:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-24 23:24:22,708:INFO:create_model() successfully completed......................................
2024-03-24 23:24:22,799:INFO:_master_model_container: 14
2024-03-24 23:24:22,799:INFO:_display_container: 2
2024-03-24 23:24:22,799:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-24 23:24:22,799:INFO:compare_models() successfully completed......................................
