{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "\"title\": \"JBIG코드실습_타이타닉(1주차)\"\n",
    "\"author\": \"이정재\"\n",
    "\"date\": \"2024-03-24\"\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./train_1.csv')\n",
    "train.head()\n",
    "set(train['Pclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 데이터 불러오기\n",
    "train = pd.read_csv('./train_1.csv')\n",
    "\n",
    "# 전처리 (필요시 전처리 추가할 것)#########################################################################\n",
    "train['Age'] = train['Age'].fillna(29)\n",
    "train['Sex'] = train['Sex'].map({'male': 1, 'female': 0})\n",
    "# 위 5개 칼럼만 사용할 것\n",
    "train = train[[ 'Pclass', 'SibSp', 'Age', 'Sex', 'Survived']] \n",
    "\n",
    "# X값과 y값 구하기\n",
    "X = train.drop(columns=['Survived'])\n",
    "y = train['Survived']\n",
    "\n",
    "# 데이터 세트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest의 정확도: 0.8268156424581006\n"
     ]
    }
   ],
   "source": [
    "# 랜덤포레스트를 정의 및 학습하고 Accuracy로 평가해보세요\n",
    "\n",
    "# 랜덤 포레스트 정의\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 랜덤 포레스트 학습\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "# 정확도 평가\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest의 정확도:\", accuracy_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM의 정확도: 0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "# LightGBM를 정의 및 학습하고 Accuracy로 평가해보세요\n",
    "\n",
    "# LightGBM 모델 정의\n",
    "lgb_classifier = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# LightGBM 모델 학습\n",
    "lgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_lgb = lgb_classifier.predict(X_test)\n",
    "\n",
    "# 정확도 평가\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
    "print(\"LightGBM의 정확도:\", accuracy_lgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest의 정확도: 0.8044692737430168\n"
     ]
    }
   ],
   "source": [
    "# 둘 중 더 높은 Accuracy가 나온 모델의 하이퍼 파라미터 default값을 '구글링'을 통해 확인하고 변경해보세요(Grid_Search말고 직접 바꿀것)\n",
    "\n",
    "\n",
    "# 랜덤 포레스트 정의\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=13,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',\n",
    "    max_depth=7,\n",
    "    max_leaf_nodes=10,\n",
    "    random_state=42)\n",
    "\n",
    "# 랜덤 포레스트 학습\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "# 정확도 평가\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest의 정확도:\", accuracy_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/ag/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "LightGBM의 정확도: 0.8268156424581006\n"
     ]
    }
   ],
   "source": [
    "# LightGBM를 정의 및 학습하고 Accuracy로 평가해보세요\n",
    "\n",
    "# LightGBM 모델 정의\n",
    "lgb_classifier = lgb.LGBMClassifier(\n",
    "    num_iterations=130,\n",
    "    learning_rate=0.09,\n",
    "    max_depth=6,\n",
    "    min_data_in_leaf=30,\n",
    "    num_leaves=40,\n",
    "    boosting='gbdt',\n",
    "    bagging_fraction=1.0,\n",
    "    feature_fraction=1.0,\n",
    "    random_state=42)\n",
    "\n",
    "# LightGBM 모델 학습\n",
    "lgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_lgb = lgb_classifier.predict(X_test)\n",
    "\n",
    "# 정확도 평가\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
    "print(\"LightGBM의 정확도:\", accuracy_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/ag/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "VotingClassifier의 정확도: 0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "# VotingClassifier를 통해서 앙상블;보팅 한후 Accuracy를 계산해보세요\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# VotingClassifier 정의\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('random_forest', rf_classifier),\n",
    "    ('lightgbm', lgb_classifier)\n",
    "])\n",
    "\n",
    "# VotingClassifier 학습\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred_voting = voting_classifier.predict(X_test)\n",
    "\n",
    "# 정확도 평가\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "print(\"VotingClassifier의 정확도:\", accuracy_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
