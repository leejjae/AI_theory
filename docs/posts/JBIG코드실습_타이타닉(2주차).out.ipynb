{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# JBIG코드실습_타이타닉(2주차)\n",
        "\n",
        "이정재  \n",
        "2024-03-24"
      ],
      "id": "7944f1b1-a21c-4794-8eff-a935015dd1fa"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "id": "cell-1"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = pd.read_csv('./train_2.csv')\n",
        "train.head()"
      ],
      "id": "cell-2"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nAAAAAElFTkSuQmCC\n"
          }
        }
      ],
      "source": [
        "# Matplolib 으로 Survived의 분포 확인\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "survived_counts = train['Survived'].value_counts()\n",
        "\n",
        "# 막대 그래프 그리기\n",
        "plt.bar(survived_counts.index, survived_counts.values)\n",
        "\n",
        "# 그래프에 제목과 레이블 추가\n",
        "plt.title('Survived Distribution')\n",
        "plt.xlabel('Survived')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# x축의 눈금 레이블 설정\n",
        "plt.xticks(survived_counts.index, ['Not Survived', 'Survived'])\n",
        "\n",
        "# 그래프 출력\n",
        "plt.show()\n",
        "\n"
      ],
      "id": "cell-3"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 불러오기\n",
        "train = pd.read_csv('./train_2.csv')\n",
        "\n",
        "# 전처리 (필요시 전처리 추가할 것)#########################################################################\n",
        "train['Age'] = train['Age'].fillna(29)\n",
        "train['Sex'] = train['Sex'].map({'male': 1, 'female': 0})\n",
        "# 위 5개 칼럼만 사용할 것\n",
        "train = train[[ 'Pclass', 'SibSp', 'Age', 'Sex', 'Survived']] \n",
        "\n",
        "# X값과 y값 구하기\n",
        "X = train.drop(columns=['Survived'])\n",
        "y = train['Survived']\n",
        "\n",
        "# 데이터 세트 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "id": "cell-4"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 스케일링과 데이터 인코딩이 필요한 칼럼을 확인한 후 전처리를 진행하세요\n"
      ],
      "id": "cell-5"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
            "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
            "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
            "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
            "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
            "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
            "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
            "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
            "[LightGBM] [Info] Number of positive: 1, number of negative: 1"
          ]
        }
      ],
      "source": [
        "# PyCaret으로 가장 좋은 성능을 보이는 모델을 찾으세요.\n",
        "from pycaret.classification import *\n",
        "# PyCaret 설정\n",
        "exp1 = setup(train, target='Survived', session_id=123,use_gpu=True) \n",
        "\n",
        "# 모델 비교 및 평가\n",
        "best_model = compare_models()\n"
      ],
      "id": "cell-6"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 150}\n",
            "Best Score: 0.8327788588286987"
          ]
        }
      ],
      "source": [
        "# PyCaret에서 찾은 모델을 \n",
        "# 직접 sklearn의 GridSearch를 통해 하이퍼 파라미터를 튜닝해보세요.\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Gradient Boosting Classifier 모델 정의\n",
        "gb_classifier = GradientBoostingClassifier()\n",
        "\n",
        "# 탐색할 하이퍼파라미터 그리드 정의\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5]\n",
        "}\n",
        "\n",
        "# GridSearchCV를 사용하여 하이퍼파라미터 튜닝\n",
        "grid_search = GridSearchCV(estimator=gb_classifier, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# 최적의 하이퍼파라미터와 점수 출력\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)\n"
      ],
      "id": "cell-7"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Scores: [0.84916201 0.8258427  0.79775281 0.80898876 0.83707865]\n",
            "Mean CV Score: 0.8237649865042999"
          ]
        }
      ],
      "source": [
        "# best params로 교차검증 및 StratifiedKFold를 진행하세요.\n",
        "# 최적의 하이퍼파라미터로 교차검증 및 StratifiedKFold 진행\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "best_params = grid_search.best_params_\n",
        "gb_classifier = GradientBoostingClassifier(**best_params)\n",
        "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(gb_classifier, X, y, cv=stratified_kfold)\n",
        "\n",
        "# 교차검증 결과 출력\n",
        "print(\"Cross Validation Scores:\", cv_scores)\n",
        "print(\"Mean CV Score:\", cv_scores.mean())"
      ],
      "id": "cell-8"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8731762065095399"
          ]
        }
      ],
      "source": [
        "# 앙상블 기법 중 배깅을 사용해보세요.\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# 데이터를 훈련 세트와 테스트 세트로 나눔\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 배깅 분류기 정의\n",
        "bagging_classifier = BaggingClassifier(gb_classifier, n_estimators=10, random_state=42)\n",
        "\n",
        "# 배깅 분류기를 훈련 데이터에 적합\n",
        "gb_classifier.fit(X, y)\n",
        "\n",
        "# 테스트 데이터에 대한 예측\n",
        "y_pred = gb_classifier.predict(X)\n",
        "\n",
        "# 정확도 평가\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "id": "cell-9"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  }
}